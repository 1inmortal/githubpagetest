{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross Validation\n",
        "\n",
        "Este notebook implementa técnicas de validación cruzada para evaluar modelos de machine learning.\n",
        "\n",
        "## Características:\n",
        "- K-Fold Cross Validation\n",
        "- Stratified K-Fold para problemas de clasificación\n",
        "- Time Series Split para datos temporales\n",
        "- Grid Search con Cross Validation\n",
        "- Comparación de métricas entre diferentes folds\n",
        "- Visualización de resultados de validación cruzada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports y configuración\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import (\n",
        "    cross_val_score, KFold, StratifiedKFold, TimeSeriesSplit,\n",
        "    GridSearchCV, cross_validate, validation_curve\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    mean_squared_error, r2_score, make_scorer\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuración general de gráficos\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuración del dataset\n",
        "DATA_PATH = Path(r\"C:\\Users\\INMORTAL\\OneDrive\\Documentos\\python\\notebooks\\modelos\\Data\\Global_Cybersecurity_Threats_2015-2024.csv\")\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Shape del dataset:\", df.shape)\n",
        "print(\"Columnas:\", list(df.columns))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparación de datos para clasificación\n",
        "print(\"=== PREPARACIÓN DE DATOS PARA CLASIFICACIÓN ===\")\n",
        "\n",
        "# Para clasificación: Attack Type como objetivo\n",
        "y_class = df['Attack Type']\n",
        "X_class = df.drop(columns=['Attack Type'])\n",
        "\n",
        "# Mapear etiquetas no numéricas a códigos\n",
        "if not pd.api.types.is_numeric_dtype(y_class):\n",
        "    y_class = y_class.astype('category').cat.codes\n",
        "    print(f\"Mapeo de etiquetas a códigos aplicado sobre 'Attack Type'.\")\n",
        "\n",
        "# One-hot encoding para columnas categóricas en X\n",
        "X_class = pd.get_dummies(X_class, drop_first=True)\n",
        "\n",
        "print(\"Shape X_class:\", X_class.shape, \"- y_class:\", y_class.shape)\n",
        "print(\"Clases en y_class y conteo:\")\n",
        "print(y_class.value_counts())\n",
        "\n",
        "# Escalado para clasificación\n",
        "scaler_class = StandardScaler()\n",
        "X_class_scaled = scaler_class.fit_transform(X_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparación de datos para regresión\n",
        "print(\"\\n=== PREPARACIÓN DE DATOS PARA REGRESIÓN ===\")\n",
        "\n",
        "# Para regresión: Financial Loss como objetivo\n",
        "y_reg = df['Financial Loss (in Million $)']\n",
        "X_reg = df[['Number of Affected Users', 'Year']]  # Variables numéricas simples\n",
        "\n",
        "print(\"Shape X_reg:\", X_reg.shape, \"- y_reg:\", y_reg.shape)\n",
        "print(\"Estadísticas de y_reg:\")\n",
        "print(y_reg.describe())\n",
        "\n",
        "# Escalado para regresión\n",
        "scaler_reg = StandardScaler()\n",
        "X_reg_scaled = scaler_reg.fit_transform(X_reg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. K-Fold Cross Validation para Clasificación\n",
        "print(\"=== K-FOLD CROSS VALIDATION PARA CLASIFICACIÓN ===\")\n",
        "\n",
        "# Crear el modelo\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=RANDOM_STATE)\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# Evaluar con diferentes métricas\n",
        "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
        "cv_results = cross_validate(log_reg, X_class_scaled, y_class, \n",
        "                           cv=kfold, scoring=scoring, return_train_score=True)\n",
        "\n",
        "print(\"Resultados K-Fold (5 folds):\")\n",
        "for metric in scoring:\n",
        "    test_scores = cv_results[f'test_{metric}']\n",
        "    train_scores = cv_results[f'train_{metric}']\n",
        "    print(f\"{metric}:\")\n",
        "    print(f\"  Test:  {test_scores.mean():.4f} (+/- {test_scores.std() * 2:.4f})\")\n",
        "    print(f\"  Train: {train_scores.mean():.4f} (+/- {train_scores.std() * 2:.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Stratified K-Fold para Clasificación\n",
        "print(\"=== STRATIFIED K-FOLD PARA CLASIFICACIÓN ===\")\n",
        "\n",
        "# Stratified K-Fold mantiene la proporción de clases en cada fold\n",
        "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "cv_results_stratified = cross_validate(log_reg, X_class_scaled, y_class, \n",
        "                                      cv=stratified_kfold, scoring=scoring, \n",
        "                                      return_train_score=True)\n",
        "\n",
        "print(\"Resultados Stratified K-Fold (5 folds):\")\n",
        "for metric in scoring:\n",
        "    test_scores = cv_results_stratified[f'test_{metric}']\n",
        "    train_scores = cv_results_stratified[f'train_{metric}']\n",
        "    print(f\"{metric}:\")\n",
        "    print(f\"  Test:  {test_scores.mean():.4f} (+/- {test_scores.std() * 2:.4f})\")\n",
        "    print(f\"  Train: {train_scores.mean():.4f} (+/- {train_scores.std() * 2:.4f})\")\n",
        "    print()\n",
        "\n",
        "# Comparar con K-Fold normal\n",
        "print(\"Comparación K-Fold vs Stratified K-Fold:\")\n",
        "print(\"Accuracy Test Scores:\")\n",
        "print(f\"  K-Fold:        {cv_results['test_accuracy'].mean():.4f} (+/- {cv_results['test_accuracy'].std() * 2:.4f})\")\n",
        "print(f\"  Stratified:    {cv_results_stratified['test_accuracy'].mean():.4f} (+/- {cv_results_stratified['test_accuracy'].std() * 2:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Cross Validation para Regresión\n",
        "print(\"=== CROSS VALIDATION PARA REGRESIÓN ===\")\n",
        "\n",
        "# Crear el modelo de regresión\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# K-Fold para regresión\n",
        "kfold_reg = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# Métricas para regresión\n",
        "scoring_reg = ['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']\n",
        "\n",
        "cv_results_reg = cross_validate(lin_reg, X_reg_scaled, y_reg, \n",
        "                               cv=kfold_reg, scoring=scoring_reg, \n",
        "                               return_train_score=True)\n",
        "\n",
        "print(\"Resultados K-Fold para Regresión (5 folds):\")\n",
        "for metric in scoring_reg:\n",
        "    test_scores = cv_results_reg[f'test_{metric}']\n",
        "    train_scores = cv_results_reg[f'train_{metric}']\n",
        "    \n",
        "    # Convertir MSE y MAE a valores positivos para interpretación\n",
        "    if 'neg_' in metric:\n",
        "        test_scores = -test_scores\n",
        "        train_scores = -train_scores\n",
        "        metric_name = metric.replace('neg_', '')\n",
        "    else:\n",
        "        metric_name = metric\n",
        "    \n",
        "    print(f\"{metric_name}:\")\n",
        "    print(f\"  Test:  {test_scores.mean():.4f} (+/- {test_scores.std() * 2:.4f})\")\n",
        "    print(f\"  Train: {train_scores.mean():.4f} (+/- {train_scores.std() * 2:.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Time Series Split (para datos temporales)\n",
        "print(\"=== TIME SERIES SPLIT ===\")\n",
        "\n",
        "# Ordenar datos por año para simular serie temporal\n",
        "df_sorted = df.sort_values('Year').reset_index(drop=True)\n",
        "X_ts = df_sorted[['Number of Affected Users']].values\n",
        "y_ts = df_sorted['Financial Loss (in Million $)'].values\n",
        "\n",
        "# Time Series Split\n",
        "ts_split = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "print(\"Time Series Split (3 folds):\")\n",
        "for fold, (train_idx, test_idx) in enumerate(ts_split.split(X_ts)):\n",
        "    X_train_ts, X_test_ts = X_ts[train_idx], X_ts[test_idx]\n",
        "    y_train_ts, y_test_ts = y_ts[train_idx], y_ts[test_idx]\n",
        "    \n",
        "    # Entrenar modelo\n",
        "    model_ts = LinearRegression()\n",
        "    model_ts.fit(X_train_ts, y_train_ts)\n",
        "    \n",
        "    # Predecir y evaluar\n",
        "    y_pred_ts = model_ts.predict(X_test_ts)\n",
        "    mse = mean_squared_error(y_test_ts, y_pred_ts)\n",
        "    r2 = r2_score(y_test_ts, y_pred_ts)\n",
        "    \n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"  Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
        "    print(f\"  MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Grid Search con Cross Validation\n",
        "print(\"=== GRID SEARCH CON CROSS VALIDATION ===\")\n",
        "\n",
        "# Definir parámetros para búsqueda\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'max_iter': [100, 200, 500]\n",
        "}\n",
        "\n",
        "# Crear GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=RANDOM_STATE),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Ejecutar búsqueda\n",
        "grid_search.fit(X_class_scaled, y_class)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "print(\"Mejor score:\", grid_search.best_score_)\n",
        "print()\n",
        "\n",
        "# Mostrar resultados de todos los parámetros\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "print(\"Resultados de Grid Search:\")\n",
        "print(results_df[['param_C', 'param_max_iter', 'mean_test_score', 'std_test_score']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Validation Curve\n",
        "print(\"=== VALIDATION CURVE ===\")\n",
        "\n",
        "# Crear validation curve para el parámetro C de LogisticRegression\n",
        "param_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "train_scores, test_scores = validation_curve(\n",
        "    LogisticRegression(random_state=RANDOM_STATE),\n",
        "    X_class_scaled, y_class,\n",
        "    param_name='C',\n",
        "    param_range=param_range,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calcular media y desviación estándar\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Visualizar validation curve\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.semilogx(param_range, train_mean, 'o-', color='blue', label='Training score')\n",
        "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
        "plt.semilogx(param_range, test_mean, 'o-', color='red', label='Cross-validation score')\n",
        "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.1, color='red')\n",
        "\n",
        "plt.xlabel('Parámetro C')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Validation Curve - Logistic Regression')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Validation Curve completada. El gráfico muestra cómo varía el rendimiento con diferentes valores del parámetro C.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Comparación de Modelos con Cross Validation\n",
        "print(\"=== COMPARACIÓN DE MODELOS CON CROSS VALIDATION ===\")\n",
        "\n",
        "# Definir modelos para comparar\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=200, random_state=RANDOM_STATE),\n",
        "    'KNN (k=3)': KNeighborsClassifier(n_neighbors=3),\n",
        "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
        "    'KNN (k=7)': KNeighborsClassifier(n_neighbors=7)\n",
        "}\n",
        "\n",
        "# Evaluar cada modelo\n",
        "results_comparison = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_class_scaled, y_class, cv=5, scoring='accuracy')\n",
        "    results_comparison[name] = scores\n",
        "    print(f\"{name}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
        "\n",
        "# Visualizar comparación\n",
        "plt.figure(figsize=(12, 6))\n",
        "model_names = list(results_comparison.keys())\n",
        "model_scores = [results_comparison[name] for name in model_names]\n",
        "\n",
        "plt.boxplot(model_scores, labels=model_names)\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Comparación de Modelos con Cross Validation')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_model = max(results_comparison.items(), key=lambda x: x[1].mean())\n",
        "print(f\"\\nMejor modelo: {best_model[0]} con accuracy promedio de {best_model[1].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Análisis de Varianza en Cross Validation\n",
        "print(\"=== ANÁLISIS DE VARIANZA EN CROSS VALIDATION ===\")\n",
        "\n",
        "# Analizar la varianza entre folds para diferentes números de folds\n",
        "fold_numbers = [3, 5, 10]\n",
        "variance_analysis = {}\n",
        "\n",
        "for n_folds in fold_numbers:\n",
        "    kfold_var = KFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "    scores = cross_val_score(LogisticRegression(max_iter=200, random_state=RANDOM_STATE), \n",
        "                            X_class_scaled, y_class, cv=kfold_var, scoring='accuracy')\n",
        "    variance_analysis[n_folds] = scores\n",
        "    print(f\"{n_folds}-Fold CV: Mean={scores.mean():.4f}, Std={scores.std():.4f}\")\n",
        "\n",
        "# Visualizar análisis de varianza\n",
        "plt.figure(figsize=(12, 6))\n",
        "fold_labels = [f'{n}-Fold' for n in fold_numbers]\n",
        "fold_scores = [variance_analysis[n] for n in fold_numbers]\n",
        "\n",
        "plt.boxplot(fold_scores, labels=fold_labels)\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Análisis de Varianza: Diferentes Números de Folds')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nObservaciones:\")\n",
        "print(\"- Más folds generalmente reducen la varianza pero aumentan el tiempo de cómputo\")\n",
        "print(\"- 5-fold es un buen balance entre estabilidad y eficiencia\")\n",
        "print(\"- La varianza alta puede indicar que el modelo es inestable o que hay datos problemáticos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Resumen y Recomendaciones\n",
        "print(\"=== RESUMEN Y RECOMENDACIONES ===\")\n",
        "\n",
        "print(\"Técnicas de Cross Validation implementadas:\")\n",
        "print(\"1. K-Fold Cross Validation: División aleatoria en k folds\")\n",
        "print(\"2. Stratified K-Fold: Mantiene proporción de clases en cada fold\")\n",
        "print(\"3. Time Series Split: Para datos temporales (no aleatorio)\")\n",
        "print(\"4. Grid Search: Búsqueda de hiperparámetros con CV\")\n",
        "print(\"5. Validation Curve: Análisis de sensibilidad de parámetros\")\n",
        "print(\"6. Comparación de modelos: Evaluación múltiple con CV\")\n",
        "print(\"7. Análisis de varianza: Estabilidad con diferentes números de folds\")\n",
        "\n",
        "print(\"\\nRecomendaciones:\")\n",
        "print(\"- Usar Stratified K-Fold para problemas de clasificación desbalanceados\")\n",
        "print(\"- Time Series Split para datos con dependencia temporal\")\n",
        "print(\"- 5-fold CV es generalmente suficiente para la mayoría de casos\")\n",
        "print(\"- Grid Search es útil para optimizar hiperparámetros\")\n",
        "print(\"- Validation curves ayudan a detectar overfitting/underfitting\")\n",
        "print(\"- Comparar múltiples modelos para encontrar el mejor\")\n",
        "print(\"- La varianza alta en CV puede indicar problemas en los datos o modelo\")\n",
        "\n",
        "print(\"\\nMétricas importantes a considerar:\")\n",
        "print(\"- Accuracy: Proporción de predicciones correctas\")\n",
        "print(\"- Precision: Proporción de positivos predichos que son realmente positivos\")\n",
        "print(\"- Recall: Proporción de positivos reales que fueron predichos correctamente\")\n",
        "print(\"- F1-Score: Media armónica entre precision y recall\")\n",
        "print(\"- R²: Coeficiente de determinación para regresión\")\n",
        "print(\"- MSE/MAE: Errores cuadráticos/absolutos medios para regresión\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
