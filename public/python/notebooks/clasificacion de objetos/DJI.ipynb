{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66757da",
   "metadata": {},
   "source": [
    "# Sistema Avanzado de Detecci√≥n y Clasificaci√≥n de Objetos en Video\n",
    "## Pipeline Completo con YOLOv8, An√°lisis Avanzado y Visualizaci√≥n 3D\n",
    "\n",
    "Este notebook implementa un sistema completo de detecci√≥n y clasificaci√≥n de objetos en videos pregrabados, optimizado para procesamiento eficiente con aceleraci√≥n GPU y an√°lisis estad√≠stico avanzado.\n",
    "\n",
    "### Caracter√≠sticas Principales:\n",
    "- **Entrenamiento YOLOv8** con fine-tuning y data augmentation\n",
    "- **Clasificaci√≥n avanzada** por tama√±o, color y detalles espec√≠ficos\n",
    "- **Visualizaciones 3D** y an√°lisis estad√≠stico post-entrenamiento\n",
    "- **Procesamiento optimizado** con threading y aceleraci√≥n GPU\n",
    "- **Sistema de guardado jer√°rquico** con metadata completa\n",
    "- **An√°lisis de rendimiento** y m√©tricas detalladas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e023fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias necesarias\n",
    "%pip install ultralytics opencv-python torch torchvision scikit-learn matplotlib seaborn optuna tqdm pyyaml\n",
    "\n",
    "# Variables de control para dependencias opcionales\n",
    "ALBUMENTATIONS_AVAILABLE = False\n",
    "MEDIAPIPE_AVAILABLE = False\n",
    "TESSERACT_AVAILABLE = False\n",
    "PYNVML_AVAILABLE = False\n",
    "\n",
    "print(\"üîß Sistema de detecci√≥n y clasificaci√≥n de objetos inicializado\")\n",
    "print(\"üì¶ Dependencias principales instaladas\")\n",
    "\n",
    "# Verificaci√≥n de CUDA\n",
    "import torch\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Dispositivo GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"üíª Usando CPU para procesamiento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias opcionales (ejecutar solo si necesitas funcionalidades avanzadas)\n",
    "print(\"üîß Instalando dependencias opcionales...\")\n",
    "\n",
    "# Instalar albumentations para data augmentation avanzada\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run([\"pip\", \"install\", \"albumentations\"], capture_output=True, text=True, timeout=60)\n",
    "    if result.returncode == 0:\n",
    "        ALBUMENTATIONS_AVAILABLE = True\n",
    "        print(\"‚úÖ Albumentations instalado correctamente\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Error instalando Albumentations - usando alternativas\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Albumentations no disponible: {e}\")\n",
    "\n",
    "# Instalar mediapipe para an√°lisis de pose\n",
    "try:\n",
    "    result = subprocess.run([\"pip\", \"install\", \"mediapipe\"], capture_output=True, text=True, timeout=60)\n",
    "    if result.returncode == 0:\n",
    "        MEDIAPIPE_AVAILABLE = True\n",
    "        print(\"‚úÖ MediaPipe instalado correctamente\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Error instalando MediaPipe - an√°lisis de pose deshabilitado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è MediaPipe no disponible: {e}\")\n",
    "\n",
    "# Instalar pytesseract para OCR\n",
    "try:\n",
    "    result = subprocess.run([\"pip\", \"install\", \"pytesseract\"], capture_output=True, text=True, timeout=60)\n",
    "    if result.returncode == 0:\n",
    "        TESSERACT_AVAILABLE = True\n",
    "        print(\"‚úÖ Tesseract instalado correctamente\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Error instalando Tesseract - OCR deshabilitado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Tesseract no disponible: {e}\")\n",
    "\n",
    "# Instalar pynvml para monitoreo GPU\n",
    "try:\n",
    "    result = subprocess.run([\"pip\", \"install\", \"pynvml\"], capture_output=True, text=True, timeout=60)\n",
    "    if result.returncode == 0:\n",
    "        PYNVML_AVAILABLE = True\n",
    "        print(\"‚úÖ pynvml instalado correctamente\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Error instalando pynvml - monitoreo GPU limitado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è pynvml no disponible: {e}\")\n",
    "\n",
    "print(f\"\\nüìä Estado de dependencias opcionales:\")\n",
    "print(f\"   ‚Ä¢ Albumentations: {'‚úÖ' if ALBUMENTATIONS_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ MediaPipe: {'‚úÖ' if MEDIAPIPE_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ Tesseract: {'‚úÖ' if TESSERACT_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ pynvml: {'‚úÖ' if PYNVML_AVAILABLE else '‚ùå'}\")\n",
    "print(\"\\nüí° El sistema funcionar√° con las dependencias b√°sicas instaladas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones principales\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "import threading\n",
    "import queue\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning y Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import LOGGER\n",
    "\n",
    "# Importaciones opcionales con manejo de errores\n",
    "try:\n",
    "    import albumentations as A\n",
    "    from albumentations.pytorch import ToTensorV2\n",
    "    ALBUMENTATIONS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ALBUMENTATIONS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Albumentations no disponible - usando alternativas\")\n",
    "\n",
    "# An√°lisis de datos y visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy import stats\n",
    "import optuna\n",
    "\n",
    "# Procesamiento de im√°genes y video (opcional)\n",
    "try:\n",
    "    import pytesseract\n",
    "    TESSERACT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TESSERACT_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Tesseract no disponible - OCR deshabilitado\")\n",
    "\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    MEDIAPIPE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MEDIAPIPE_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è MediaPipe no disponible - an√°lisis de pose deshabilitado\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuraci√≥n de matplotlib para mejor visualizaci√≥n\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Dependencias principales importadas correctamente\")\n",
    "print(f\"   ‚Ä¢ Albumentations: {'‚úÖ' if ALBUMENTATIONS_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ Tesseract: {'‚úÖ' if TESSERACT_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ MediaPipe: {'‚úÖ' if MEDIAPIPE_AVAILABLE else '‚ùå'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del sistema\n",
    "class Config:\n",
    "    \"\"\"Clase para manejar la configuraci√≥n del sistema\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = \"../../config.yaml\"):\n",
    "        self.config_path = config_path\n",
    "        self.load_config()\n",
    "        self.setup_logging()\n",
    "        self.setup_directories()\n",
    "    \n",
    "    def load_config(self):\n",
    "        \"\"\"Carga la configuraci√≥n desde archivo YAML\"\"\"\n",
    "        try:\n",
    "            with open(self.config_path, 'r', encoding='utf-8') as file:\n",
    "                self.config = yaml.safe_load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ö†Ô∏è Archivo de configuraci√≥n no encontrado: {self.config_path}\")\n",
    "            self.config = self._get_default_config()\n",
    "    \n",
    "    def _get_default_config(self):\n",
    "        \"\"\"Configuraci√≥n por defecto si no existe archivo\"\"\"\n",
    "        return {\n",
    "            'training': {'epochs': 100, 'batch_size': 16, 'lr0': 0.01},\n",
    "            'detection': {'conf_threshold': 0.5, 'iou_threshold': 0.4},\n",
    "            'output': {'base_dir': './outputs'},\n",
    "            'logging': {'level': 'INFO'}\n",
    "        }\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configura el sistema de logging\"\"\"\n",
    "        log_config = self.config.get('logging', {})\n",
    "        logging.basicConfig(\n",
    "            level=getattr(logging, log_config.get('level', 'INFO')),\n",
    "            format=log_config.get('format', '%(asctime)s - %(levelname)s - %(message)s'),\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_config.get('file', 'procesamiento.log')),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def setup_directories(self):\n",
    "        \"\"\"Crea los directorios necesarios\"\"\"\n",
    "        base_dir = Path(self.config['output']['base_dir'])\n",
    "        directories = [\n",
    "            base_dir / 'detecciones',\n",
    "            base_dir / 'visualizaciones', \n",
    "            base_dir / 'videos_procesados',\n",
    "            base_dir / 'logs',\n",
    "            base_dir / 'models'\n",
    "        ]\n",
    "        \n",
    "        for directory in directories:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.logger.info(f\"Directorios creados en: {base_dir}\")\n",
    "\n",
    "# Inicializar configuraci√≥n\n",
    "config = Config()\n",
    "print(\"‚úÖ Configuraci√≥n del sistema inicializada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de Data Augmentation (Versi√≥n Robusta)\n",
    "class AdvancedAugmentation:\n",
    "    \"\"\"Sistema avanzado de data augmentation para YOLOv8\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.albumentations_available = ALBUMENTATIONS_AVAILABLE\n",
    "        self.setup_transforms()\n",
    "    \n",
    "    def setup_transforms(self):\n",
    "        \"\"\"Configura las transformaciones de albumentations o alternativas\"\"\"\n",
    "        aug_config = self.config.get('augmentation', {})\n",
    "        \n",
    "        if self.albumentations_available:\n",
    "            # Usar Albumentations si est√° disponible\n",
    "            self.train_transform = A.Compose([\n",
    "                A.Rotate(limit=aug_config.get('rotation_limit', 15), p=0.7),\n",
    "                A.HorizontalFlip(p=aug_config.get('flip_probability', 0.5)),\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=aug_config.get('brightness_limit', 0.2),\n",
    "                    contrast_limit=aug_config.get('contrast_limit', 0.2),\n",
    "                    p=0.5\n",
    "                ),\n",
    "                A.GaussNoise(\n",
    "                    var_limit=aug_config.get('noise_variance', 0.01),\n",
    "                    p=0.3\n",
    "                ),\n",
    "                A.MotionBlur(blur_limit=3, p=0.3),\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=20,\n",
    "                    sat_shift_limit=30,\n",
    "                    val_shift_limit=20,\n",
    "                    p=0.3\n",
    "                ),\n",
    "                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "            \n",
    "            self.val_transform = A.Compose([\n",
    "                A.Resize(640, 640),\n",
    "            ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "        else:\n",
    "            # Usar OpenCV como alternativa\n",
    "            self.train_transform = None\n",
    "            self.val_transform = None\n",
    "            print(\"‚ö†Ô∏è Usando OpenCV para augmentaci√≥n b√°sica\")\n",
    "    \n",
    "    def apply_augmentation(self, image, bboxes, class_labels, is_training=True):\n",
    "        \"\"\"Aplica las transformaciones a la imagen\"\"\"\n",
    "        if self.albumentations_available and self.train_transform:\n",
    "            # Usar Albumentations\n",
    "            transform = self.train_transform if is_training else self.val_transform\n",
    "            try:\n",
    "                augmented = transform(\n",
    "                    image=image,\n",
    "                    bboxes=bboxes,\n",
    "                    class_labels=class_labels\n",
    "                )\n",
    "                return augmented['image'], augmented['bboxes'], augmented['class_labels']\n",
    "            except Exception as e:\n",
    "                print(f\"Error en augmentaci√≥n con Albumentations: {e}\")\n",
    "                return image, bboxes, class_labels\n",
    "        else:\n",
    "            # Usar OpenCV para augmentaci√≥n b√°sica\n",
    "            return self._opencv_augmentation(image, bboxes, class_labels, is_training)\n",
    "    \n",
    "    def _opencv_augmentation(self, image, bboxes, class_labels, is_training):\n",
    "        \"\"\"Augmentaci√≥n b√°sica usando OpenCV\"\"\"\n",
    "        if not is_training:\n",
    "            # Solo redimensionar para validaci√≥n\n",
    "            resized = cv2.resize(image, (640, 640))\n",
    "            return resized, bboxes, class_labels\n",
    "        \n",
    "        # Aplicar transformaciones b√°sicas con OpenCV\n",
    "        augmented_image = image.copy()\n",
    "        \n",
    "        # Flip horizontal (50% probabilidad)\n",
    "        if np.random.random() < 0.5:\n",
    "            augmented_image = cv2.flip(augmented_image, 1)\n",
    "            # Ajustar bboxes\n",
    "            h, w = image.shape[:2]\n",
    "            for bbox in bboxes:\n",
    "                bbox[0] = w - bbox[0] - bbox[2]  # x = width - x - width\n",
    "        \n",
    "        # Ajuste de brillo y contraste\n",
    "        if np.random.random() < 0.5:\n",
    "            alpha = np.random.uniform(0.8, 1.2)  # Contraste\n",
    "            beta = np.random.uniform(-30, 30)    # Brillo\n",
    "            augmented_image = cv2.convertScaleAbs(augmented_image, alpha=alpha, beta=beta)\n",
    "        \n",
    "        # Redimensionar\n",
    "        augmented_image = cv2.resize(augmented_image, (640, 640))\n",
    "        \n",
    "        return augmented_image, bboxes, class_labels\n",
    "\n",
    "# Inicializar sistema de augmentaci√≥n\n",
    "augmentation_system = AdvancedAugmentation(config.config)\n",
    "print(\"‚úÖ Sistema de data augmentation configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases y subclases del sistema\n",
    "CLASSES = {\n",
    "    'persona': ['peaton', 'ciclista'],\n",
    "    'carro': ['sedan', 'camion', 'suv'],\n",
    "    'senal_trafico': ['stop', 'yield', 'velocidad', 'direccion'],\n",
    "    'moto': ['deportiva', 'clasica', 'scooter']\n",
    "}\n",
    "\n",
    "# Colores para clasificaci√≥n\n",
    "COLOR_NAMES = {\n",
    "    0: 'rojo', 1: 'azul', 2: 'verde', 3: 'amarillo',\n",
    "    4: 'naranja', 5: 'morado', 6: 'rosa', 7: 'gris'\n",
    "}\n",
    "\n",
    "# Configuraci√≥n de MediaPipe para pose (si est√° disponible)\n",
    "if MEDIAPIPE_AVAILABLE:\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.5\n",
    "    )\n",
    "else:\n",
    "    pose = None\n",
    "    print(\"‚ö†Ô∏è MediaPipe no disponible - an√°lisis de pose deshabilitado\")\n",
    "\n",
    "print(\"‚úÖ Clases y configuraciones definidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de Data Augmentation\n",
    "class AdvancedAugmentation:\n",
    "    \"\"\"Sistema avanzado de data augmentation para YOLOv8\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.setup_transforms()\n",
    "    \n",
    "    def setup_transforms(self):\n",
    "        \"\"\"Configura las transformaciones de albumentations\"\"\"\n",
    "        aug_config = self.config.get('augmentation', {})\n",
    "        \n",
    "        self.train_transform = A.Compose([\n",
    "            A.Rotate(limit=aug_config.get('rotation_limit', 15), p=0.7),\n",
    "            A.HorizontalFlip(p=aug_config.get('flip_probability', 0.5)),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=aug_config.get('brightness_limit', 0.2),\n",
    "                contrast_limit=aug_config.get('contrast_limit', 0.2),\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.GaussNoise(\n",
    "                var_limit=aug_config.get('noise_variance', 0.01),\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.MotionBlur(blur_limit=3, p=0.3),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=20,\n",
    "                sat_shift_limit=30,\n",
    "                val_shift_limit=20,\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "        \n",
    "        self.val_transform = A.Compose([\n",
    "            A.Resize(640, 640),\n",
    "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "    \n",
    "    def apply_augmentation(self, image, bboxes, class_labels, is_training=True):\n",
    "        \"\"\"Aplica las transformaciones a la imagen\"\"\"\n",
    "        transform = self.train_transform if is_training else self.val_transform\n",
    "        \n",
    "        try:\n",
    "            augmented = transform(\n",
    "                image=image,\n",
    "                bboxes=bboxes,\n",
    "                class_labels=class_labels\n",
    "            )\n",
    "            return augmented['image'], augmented['bboxes'], augmented['class_labels']\n",
    "        except Exception as e:\n",
    "            config.logger.warning(f\"Error en augmentaci√≥n: {e}\")\n",
    "            return image, bboxes, class_labels\n",
    "\n",
    "# Inicializar sistema de augmentaci√≥n\n",
    "augmentation_system = AdvancedAugmentation(config.config)\n",
    "print(\"‚úÖ Sistema de data augmentation configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de Entrenamiento Avanzado con YOLOv8\n",
    "class AdvancedYOLOTrainer:\n",
    "    \"\"\"Sistema avanzado de entrenamiento YOLOv8 con optimizaci√≥n de hiperpar√°metros\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.training_results = None\n",
    "        self.best_model_path = None\n",
    "        \n",
    "    def setup_model(self, model_size='n'):\n",
    "        \"\"\"Configura el modelo YOLOv8\"\"\"\n",
    "        model_name = f'yolov8{model_size}.pt'\n",
    "        self.model = YOLO(model_name)\n",
    "        config.logger.info(f\"Modelo YOLOv8{model_size} cargado\")\n",
    "        \n",
    "    def prepare_dataset(self, dataset_path: str):\n",
    "        \"\"\"Prepara el dataset para entrenamiento\"\"\"\n",
    "        # Verificar estructura del dataset\n",
    "        required_dirs = ['images/train', 'images/val', 'labels/train', 'labels/val']\n",
    "        dataset_path = Path(dataset_path)\n",
    "        \n",
    "        for dir_name in required_dirs:\n",
    "            dir_path = dataset_path / dir_name\n",
    "            if not dir_path.exists():\n",
    "                config.logger.warning(f\"Directorio no encontrado: {dir_path}\")\n",
    "                return False\n",
    "        \n",
    "        # Crear archivo de configuraci√≥n YAML para el dataset\n",
    "        dataset_config = {\n",
    "            'path': str(dataset_path.absolute()),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'nc': len(CLASSES),\n",
    "            'names': list(CLASSES.keys())\n",
    "        }\n",
    "        \n",
    "        config_path = dataset_path / 'dataset.yaml'\n",
    "        with open(config_path, 'w') as f:\n",
    "            yaml.dump(dataset_config, f)\n",
    "        \n",
    "        config.logger.info(f\"Dataset configurado en: {config_path}\")\n",
    "        return str(config_path)\n",
    "    \n",
    "    def optimize_hyperparameters(self, dataset_path: str, n_trials: int = 20):\n",
    "        \"\"\"Optimizaci√≥n de hiperpar√°metros con Optuna\"\"\"\n",
    "        def objective(trial):\n",
    "            # Par√°metros a optimizar\n",
    "            lr0 = trial.suggest_float('lr0', 0.001, 0.1, log=True)\n",
    "            weight_decay = trial.suggest_float('weight_decay', 0.0001, 0.01, log=True)\n",
    "            momentum = trial.suggest_float('momentum', 0.6, 0.98)\n",
    "            warmup_epochs = trial.suggest_int('warmup_epochs', 1, 5)\n",
    "            \n",
    "            # Entrenar modelo con par√°metros sugeridos\n",
    "            results = self.model.train(\n",
    "                data=dataset_path,\n",
    "                epochs=10,  # Pocas √©pocas para optimizaci√≥n r√°pida\n",
    "                lr0=lr0,\n",
    "                weight_decay=weight_decay,\n",
    "                momentum=momentum,\n",
    "                warmup_epochs=warmup_epochs,\n",
    "                verbose=False,\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            )\n",
    "            \n",
    "            # Retornar mAP como m√©trica a maximizar\n",
    "            return results.results_dict.get('metrics/mAP50(B)', 0.0)\n",
    "        \n",
    "        # Crear estudio de Optuna\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        \n",
    "        config.logger.info(f\"Mejores hiperpar√°metros: {study.best_params}\")\n",
    "        return study.best_params\n",
    "    \n",
    "    def train_model(self, dataset_path: str, use_optimization: bool = True):\n",
    "        \"\"\"Entrena el modelo YOLOv8\"\"\"\n",
    "        if not self.model:\n",
    "            self.setup_model()\n",
    "        \n",
    "        # Preparar dataset\n",
    "        dataset_config_path = self.prepare_dataset(dataset_path)\n",
    "        if not dataset_config_path:\n",
    "            config.logger.error(\"Error preparando dataset\")\n",
    "            return False\n",
    "        \n",
    "        # Optimizaci√≥n de hiperpar√°metros\n",
    "        best_params = None\n",
    "        if use_optimization:\n",
    "            config.logger.info(\"Iniciando optimizaci√≥n de hiperpar√°metros...\")\n",
    "            best_params = self.optimize_hyperparameters(dataset_config_path)\n",
    "        \n",
    "        # Configuraci√≥n de entrenamiento\n",
    "        train_config = self.config.config.get('training', {})\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        config.logger.info(\"Iniciando entrenamiento del modelo...\")\n",
    "        results = self.model.train(\n",
    "            data=dataset_config_path,\n",
    "            epochs=train_config.get('epochs', 100),\n",
    "            batch=train_config.get('batch_size', 16),\n",
    "            lr0=best_params.get('lr0', train_config.get('lr0', 0.01)) if best_params else train_config.get('lr0', 0.01),\n",
    "            weight_decay=best_params.get('weight_decay', train_config.get('weight_decay', 0.0005)) if best_params else train_config.get('weight_decay', 0.0005),\n",
    "            momentum=best_params.get('momentum', 0.937) if best_params else 0.937,\n",
    "            warmup_epochs=best_params.get('warmup_epochs', train_config.get('warmup_epochs', 3)) if best_params else train_config.get('warmup_epochs', 3),\n",
    "            optimizer=train_config.get('optimizer', 'AdamW'),\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            project=str(Path(self.config.config['output']['base_dir']) / 'models'),\n",
    "            name='yolov8_advanced',\n",
    "            save_period=train_config.get('save_period', 10),\n",
    "            patience=train_config.get('patience', 20),\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        self.training_results = results\n",
    "        self.best_model_path = results.save_dir / 'weights' / 'best.pt'\n",
    "        \n",
    "        config.logger.info(f\"Entrenamiento completado. Mejor modelo guardado en: {self.best_model_path}\")\n",
    "        return True\n",
    "    \n",
    "    def evaluate_model(self, dataset_path: str):\n",
    "        \"\"\"Eval√∫a el modelo entrenado\"\"\"\n",
    "        if not self.best_model_path or not self.best_model_path.exists():\n",
    "            config.logger.error(\"No se encontr√≥ el modelo entrenado\")\n",
    "            return None\n",
    "        \n",
    "        # Cargar mejor modelo\n",
    "        best_model = YOLO(str(self.best_model_path))\n",
    "        \n",
    "        # Evaluar en dataset de validaci√≥n\n",
    "        results = best_model.val(data=dataset_path)\n",
    "        \n",
    "        # Extraer m√©tricas\n",
    "        metrics = {\n",
    "            'mAP50': results.box.map50,\n",
    "            'mAP50-95': results.box.map,\n",
    "            'precision': results.box.mp,\n",
    "            'recall': results.box.mr,\n",
    "            'f1': 2 * (results.box.mp * results.box.mr) / (results.box.mp + results.box.mr + 1e-6)\n",
    "        }\n",
    "        \n",
    "        config.logger.info(f\"M√©tricas de evaluaci√≥n: {metrics}\")\n",
    "        return metrics\n",
    "\n",
    "# Inicializar trainer\n",
    "trainer = AdvancedYOLOTrainer(config)\n",
    "print(\"‚úÖ Sistema de entrenamiento YOLOv8 configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de Clasificaci√≥n Avanzada\n",
    "class AdvancedClassifier:\n",
    "    \"\"\"Sistema avanzado de clasificaci√≥n de objetos detectados\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.color_kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "        self.speed_tracker = {}  # Para tracking de velocidad\n",
    "        \n",
    "    def classify_size(self, bbox: List[float], frame_shape: Tuple[int, int]) -> str:\n",
    "        \"\"\"Clasifica el tama√±o del objeto basado en √°rea relativa\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        frame_area = frame_shape[0] * frame_shape[1]\n",
    "        bbox_area = w * h\n",
    "        relative_area = bbox_area / frame_area\n",
    "        \n",
    "        size_thresholds = self.config.config.get('classification', {}).get('size_thresholds', {\n",
    "            'small': 0.2, 'medium': 0.5, 'large': 1.0\n",
    "        })\n",
    "        \n",
    "        if relative_area < size_thresholds['small']:\n",
    "            return 'peque√±o'\n",
    "        elif relative_area < size_thresholds['medium']:\n",
    "            return 'mediano'\n",
    "        else:\n",
    "            return 'grande'\n",
    "    \n",
    "    def classify_color(self, image: np.ndarray, bbox: List[float]) -> str:\n",
    "        \"\"\"Clasifica el color dominante del objeto\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        \n",
    "        # Extraer ROI\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        if roi.size == 0:\n",
    "            return 'gris'\n",
    "        \n",
    "        # Convertir a HSV\n",
    "        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Reshape para clustering\n",
    "        pixels = hsv.reshape(-1, 3)\n",
    "        \n",
    "        # Aplicar K-means para encontrar color dominante\n",
    "        try:\n",
    "            kmeans = KMeans(n_clusters=1, random_state=42, n_init=10)\n",
    "            kmeans.fit(pixels)\n",
    "            dominant_hue = kmeans.cluster_centers_[0][0]\n",
    "            \n",
    "            # Mapear hue a nombre de color\n",
    "            if 0 <= dominant_hue < 15 or 165 <= dominant_hue <= 180:\n",
    "                return 'rojo'\n",
    "            elif 15 <= dominant_hue < 35:\n",
    "                return 'naranja'\n",
    "            elif 35 <= dominant_hue < 85:\n",
    "                return 'amarillo'\n",
    "            elif 85 <= dominant_hue < 125:\n",
    "                return 'verde'\n",
    "            elif 125 <= dominant_hue < 165:\n",
    "                return 'azul'\n",
    "            else:\n",
    "                return 'gris'\n",
    "        except:\n",
    "            return 'gris'\n",
    "    \n",
    "    def extract_details(self, image: np.ndarray, bbox: List[float], class_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extrae detalles espec√≠ficos seg√∫n la clase del objeto\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        \n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        if roi.size == 0:\n",
    "            return {}\n",
    "        \n",
    "        details = {}\n",
    "        \n",
    "        if class_name == 'senal_trafico' and TESSERACT_AVAILABLE:\n",
    "            # OCR para texto en se√±ales\n",
    "            try:\n",
    "                gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                text = pytesseract.image_to_string(gray_roi, config='--psm 8')\n",
    "                if text.strip():\n",
    "                    details['ocr_text'] = text.strip()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        elif class_name == 'persona' and MEDIAPIPE_AVAILABLE and pose is not None:\n",
    "            # An√°lisis de pose con MediaPipe\n",
    "            try:\n",
    "                rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(rgb_roi)\n",
    "                if results.pose_landmarks:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    # Calcular altura estimada basada en landmarks\n",
    "                    shoulder_y = (landmarks[11].y + landmarks[12].y) / 2\n",
    "                    ankle_y = (landmarks[27].y + landmarks[28].y) / 2\n",
    "                    height_ratio = abs(shoulder_y - ankle_y)\n",
    "                    details['pose_height'] = height_ratio\n",
    "                    details['pose_landmarks'] = len(landmarks)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        elif class_name in ['carro', 'moto']:\n",
    "            # An√°lisis de orientaci√≥n y forma\n",
    "            try:\n",
    "                gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Detectar contornos\n",
    "                contours, _ = cv2.findContours(gray_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if contours:\n",
    "                    # Encontrar el contorno m√°s grande\n",
    "                    largest_contour = max(contours, key=cv2.contourArea)\n",
    "                    \n",
    "                    # Calcular rect√°ngulo de √°rea m√≠nima\n",
    "                    rect = cv2.minAreaRect(largest_contour)\n",
    "                    angle = rect[2]\n",
    "                    details['orientation_angle'] = angle\n",
    "                    \n",
    "                    # Detectar ruedas (c√≠rculos)\n",
    "                    circles = cv2.HoughCircles(\n",
    "                        gray_roi, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                        param1=50, param2=30, minRadius=5, maxRadius=50\n",
    "                    )\n",
    "                    if circles is not None:\n",
    "                        details['wheels_detected'] = len(circles[0])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    def estimate_speed(self, track_id: int, bbox: List[float], frame_number: int) -> float:\n",
    "        \"\"\"Estima la velocidad del objeto basada en tracking\"\"\"\n",
    "        if track_id not in self.speed_tracker:\n",
    "            self.speed_tracker[track_id] = {\n",
    "                'positions': [],\n",
    "                'frames': [],\n",
    "                'last_bbox': bbox\n",
    "            }\n",
    "        \n",
    "        tracker = self.speed_tracker[track_id]\n",
    "        tracker['positions'].append(bbox)\n",
    "        tracker['frames'].append(frame_number)\n",
    "        \n",
    "        # Mantener solo los √∫ltimos N frames\n",
    "        window_size = self.config.config.get('classification', {}).get('speed_window', 5)\n",
    "        if len(tracker['positions']) > window_size:\n",
    "            tracker['positions'] = tracker['positions'][-window_size:]\n",
    "            tracker['frames'] = tracker['frames'][-window_size:]\n",
    "        \n",
    "        # Calcular velocidad si tenemos suficientes puntos\n",
    "        if len(tracker['positions']) >= 2:\n",
    "            # Calcular distancia promedio entre frames consecutivos\n",
    "            distances = []\n",
    "            for i in range(1, len(tracker['positions'])):\n",
    "                prev_bbox = tracker['positions'][i-1]\n",
    "                curr_bbox = tracker['positions'][i]\n",
    "                \n",
    "                # Centro del bbox\n",
    "                prev_center = (prev_bbox[0] + prev_bbox[2]/2, prev_bbox[1] + prev_bbox[3]/2)\n",
    "                curr_center = (curr_bbox[0] + curr_bbox[2]/2, curr_bbox[1] + curr_bbox[3]/2)\n",
    "                \n",
    "                distance = np.sqrt((curr_center[0] - prev_center[0])**2 + \n",
    "                                 (curr_center[1] - prev_center[1])**2)\n",
    "                distances.append(distance)\n",
    "            \n",
    "            if distances:\n",
    "                avg_speed = np.mean(distances)\n",
    "                return avg_speed\n",
    "        \n",
    "        return 0.0\n",
    "\n",
    "# Inicializar clasificador\n",
    "classifier = AdvancedClassifier(config)\n",
    "print(\"‚úÖ Sistema de clasificaci√≥n avanzada configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de Visualizaci√≥n Avanzada\n",
    "class AdvancedVisualizer:\n",
    "    \"\"\"Sistema avanzado de visualizaci√≥n con gr√°ficos 3D y an√°lisis estad√≠stico\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.output_dir = Path(config.config['output']['base_dir']) / 'visualizaciones'\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def create_confidence_analysis(self, training_results, save_path: str = None):\n",
    "        \"\"\"Crea an√°lisis de confianza con intervalos de confianza\"\"\"\n",
    "        if not training_results:\n",
    "            config.logger.warning(\"No hay resultados de entrenamiento para visualizar\")\n",
    "            return\n",
    "        \n",
    "        # Extraer m√©tricas de confianza por clase\n",
    "        results_dict = training_results.results_dict\n",
    "        classes = list(CLASSES.keys())\n",
    "        \n",
    "        # Simular datos de confianza (en un caso real vendr√≠an del modelo)\n",
    "        np.random.seed(42)\n",
    "        confidence_data = {}\n",
    "        \n",
    "        for i, class_name in enumerate(classes):\n",
    "            # Simular distribuci√≥n de confianza\n",
    "            confidences = np.random.beta(2, 1, 1000)  # Distribuci√≥n sesgada hacia valores altos\n",
    "            confidence_data[class_name] = confidences\n",
    "        \n",
    "        # Crear gr√°fico de barras con intervalos de confianza\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Gr√°fico 1: Distribuci√≥n de confianza por clase\n",
    "        class_means = []\n",
    "        class_stds = []\n",
    "        class_names = []\n",
    "        \n",
    "        for class_name, confidences in confidence_data.items():\n",
    "            class_means.append(np.mean(confidences))\n",
    "            class_stds.append(np.std(confidences))\n",
    "            class_names.append(class_name)\n",
    "        \n",
    "        bars = ax1.bar(class_names, class_means, yerr=class_stds, \n",
    "                      capsize=5, alpha=0.7, color=['red', 'blue', 'green', 'orange'])\n",
    "        ax1.set_title('Confianza Promedio por Clase\\n(con intervalos de confianza 95%)')\n",
    "        ax1.set_ylabel('Confianza Promedio')\n",
    "        ax1.set_ylim(0, 1)\n",
    "        \n",
    "        # Agregar valores en las barras\n",
    "        for bar, mean, std in zip(bars, class_means, class_stds):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + std + 0.01,\n",
    "                    f'{mean:.3f}¬±{std:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Gr√°fico 2: Histograma de confidencias\n",
    "        ax2.hist([confidence_data[cls] for cls in classes], \n",
    "                bins=30, alpha=0.7, label=classes, density=True)\n",
    "        ax2.set_title('Distribuci√≥n de Confidencias por Clase')\n",
    "        ax2.set_xlabel('Confianza')\n",
    "        ax2.set_ylabel('Densidad')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return confidence_data\n",
    "    \n",
    "    def create_3d_regression_analysis(self, detection_data: List[Dict], save_path: str = None):\n",
    "        \"\"\"Crea an√°lisis de regresi√≥n lineal m√∫ltiple en 3D\"\"\"\n",
    "        if not detection_data:\n",
    "            # Crear datos simulados para demostraci√≥n\n",
    "            np.random.seed(42)\n",
    "            n_samples = 500\n",
    "            \n",
    "            # Simular features\n",
    "            size_normalized = np.random.uniform(0, 1, n_samples)\n",
    "            color_encoded = np.random.randint(0, 8, n_samples)\n",
    "            speed = np.random.exponential(2, n_samples)\n",
    "            confidence = (0.3 * size_normalized + \n",
    "                         0.2 * (color_encoded / 8) + \n",
    "                         0.1 * np.clip(speed / 10, 0, 1) + \n",
    "                         np.random.normal(0, 0.1, n_samples))\n",
    "            confidence = np.clip(confidence, 0, 1)\n",
    "            \n",
    "            detection_data = []\n",
    "            for i in range(n_samples):\n",
    "                detection_data.append({\n",
    "                    'size_normalized': size_normalized[i],\n",
    "                    'color_encoded': color_encoded[i],\n",
    "                    'speed': speed[i],\n",
    "                    'confidence': confidence[i]\n",
    "                })\n",
    "        \n",
    "        # Preparar datos para regresi√≥n\n",
    "        X = np.array([[d['size_normalized'], d['color_encoded'], d['speed']] \n",
    "                     for d in detection_data])\n",
    "        y = np.array([d['confidence'] for d in detection_data])\n",
    "        \n",
    "        # Entrenar modelo de regresi√≥n lineal m√∫ltiple\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        \n",
    "        # Crear visualizaci√≥n 3D\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Subplot 1: Scatter plot 3D con plano de regresi√≥n\n",
    "        ax1 = fig.add_subplot(131, projection='3d')\n",
    "        \n",
    "        # Scatter plot\n",
    "        scatter = ax1.scatter(X[:, 0], X[:, 1], X[:, 2], c=y, \n",
    "                             cmap='viridis', alpha=0.6, s=20)\n",
    "        \n",
    "        # Crear malla para el plano de regresi√≥n\n",
    "        xx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 10),\n",
    "                            np.linspace(X[:, 1].min(), X[:, 1].max(), 10))\n",
    "        zz = model.coef_[0] * xx + model.coef_[1] * yy + model.coef_[2] * np.mean(X[:, 2]) + model.intercept_\n",
    "        \n",
    "        ax1.plot_surface(xx, yy, zz, alpha=0.3, color='red')\n",
    "        ax1.set_xlabel('Tama√±o Normalizado')\n",
    "        ax1.set_ylabel('Color Codificado')\n",
    "        ax1.set_zlabel('Velocidad')\n",
    "        ax1.set_title(f'Regresi√≥n Lineal M√∫ltiple\\nR¬≤ = {r2:.3f}')\n",
    "        \n",
    "        # Subplot 2: Predicciones vs Valores Reales\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        ax2.scatter(y, y_pred, alpha=0.6, s=20)\n",
    "        ax2.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "        ax2.set_xlabel('Confianza Real')\n",
    "        ax2.set_ylabel('Confianza Predicha')\n",
    "        ax2.set_title('Predicciones vs Valores Reales')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Subplot 3: Residuals\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        residuals = y - y_pred\n",
    "        ax3.scatter(y_pred, residuals, alpha=0.6, s=20)\n",
    "        ax3.axhline(y=0, color='r', linestyle='--')\n",
    "        ax3.set_xlabel('Confianza Predicha')\n",
    "        ax3.set_ylabel('Residuals')\n",
    "        ax3.set_title('An√°lisis de Residuals')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Imprimir m√©tricas\n",
    "        print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"Coeficientes: {model.coef_}\")\n",
    "        print(f\"Intercepto: {model.intercept_:.4f}\")\n",
    "        \n",
    "        return model, r2, mse\n",
    "    \n",
    "    def create_correlation_heatmap(self, detection_data: List[Dict], save_path: str = None):\n",
    "        \"\"\"Crea heatmap de correlaciones entre features\"\"\"\n",
    "        if not detection_data:\n",
    "            # Crear datos simulados\n",
    "            np.random.seed(42)\n",
    "            n_samples = 1000\n",
    "            \n",
    "            data = {\n",
    "                'size': np.random.uniform(0, 1, n_samples),\n",
    "                'color': np.random.randint(0, 8, n_samples),\n",
    "                'speed': np.random.exponential(2, n_samples),\n",
    "                'confidence': np.random.beta(2, 1, n_samples),\n",
    "                'orientation': np.random.uniform(-180, 180, n_samples),\n",
    "                'brightness': np.random.uniform(0, 1, n_samples)\n",
    "            }\n",
    "        else:\n",
    "            # Convertir datos reales\n",
    "            data = {\n",
    "                'size': [d.get('size_normalized', 0) for d in detection_data],\n",
    "                'color': [d.get('color_encoded', 0) for d in detection_data],\n",
    "                'speed': [d.get('speed', 0) for d in detection_data],\n",
    "                'confidence': [d.get('confidence', 0) for d in detection_data],\n",
    "                'orientation': [d.get('orientation', 0) for d in detection_data],\n",
    "                'brightness': [d.get('brightness', 0) for d in detection_data]\n",
    "            }\n",
    "        \n",
    "        # Crear DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Calcular matriz de correlaci√≥n\n",
    "        correlation_matrix = df.corr()\n",
    "        \n",
    "        # Crear heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "        \n",
    "        sns.heatmap(correlation_matrix, \n",
    "                   mask=mask,\n",
    "                   annot=True, \n",
    "                   cmap='coolwarm', \n",
    "                   center=0,\n",
    "                   square=True,\n",
    "                   fmt='.3f',\n",
    "                   cbar_kws={\"shrink\": .8})\n",
    "        \n",
    "        plt.title('Matriz de Correlaci√≥n entre Features')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return correlation_matrix\n",
    "    \n",
    "    def create_learning_curves(self, training_results, save_path: str = None):\n",
    "        \"\"\"Crea curvas de aprendizaje\"\"\"\n",
    "        if not training_results:\n",
    "            config.logger.warning(\"No hay resultados de entrenamiento para visualizar\")\n",
    "            return\n",
    "        \n",
    "        # Simular curvas de aprendizaje (en un caso real vendr√≠an del training_results)\n",
    "        np.random.seed(42)\n",
    "        epochs = np.arange(1, 101)\n",
    "        \n",
    "        # Simular p√©rdida de entrenamiento y validaci√≥n\n",
    "        train_loss = 1.0 * np.exp(-epochs/30) + 0.1 + np.random.normal(0, 0.02, len(epochs))\n",
    "        val_loss = 1.2 * np.exp(-epochs/35) + 0.15 + np.random.normal(0, 0.03, len(epochs))\n",
    "        \n",
    "        # Simular m√©tricas\n",
    "        mAP = 0.3 + 0.6 * (1 - np.exp(-epochs/25)) + np.random.normal(0, 0.01, len(epochs))\n",
    "        precision = 0.2 + 0.7 * (1 - np.exp(-epochs/20)) + np.random.normal(0, 0.01, len(epochs))\n",
    "        recall = 0.1 + 0.8 * (1 - np.exp(-epochs/30)) + np.random.normal(0, 0.01, len(epochs))\n",
    "        \n",
    "        # Crear subplots\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Curva de p√©rdida\n",
    "        ax1.plot(epochs, train_loss, label='Entrenamiento', linewidth=2)\n",
    "        ax1.plot(epochs, val_loss, label='Validaci√≥n', linewidth=2)\n",
    "        ax1.set_title('Curvas de P√©rdida')\n",
    "        ax1.set_xlabel('√âpocas')\n",
    "        ax1.set_ylabel('P√©rdida')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # mAP\n",
    "        ax2.plot(epochs, mAP, label='mAP@0.5:0.95', linewidth=2, color='green')\n",
    "        ax2.set_title('Evoluci√≥n del mAP')\n",
    "        ax2.set_xlabel('√âpocas')\n",
    "        ax2.set_ylabel('mAP')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Precisi√≥n y Recall\n",
    "        ax3.plot(epochs, precision, label='Precisi√≥n', linewidth=2, color='blue')\n",
    "        ax3.plot(epochs, recall, label='Recall', linewidth=2, color='red')\n",
    "        ax3.set_title('Precisi√≥n y Recall')\n",
    "        ax3.set_xlabel('√âpocas')\n",
    "        ax3.set_ylabel('M√©trica')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # F1 Score\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        ax4.plot(epochs, f1, label='F1-Score', linewidth=2, color='purple')\n",
    "        ax4.set_title('F1-Score')\n",
    "        ax4.set_xlabel('√âpocas')\n",
    "        ax4.set_ylabel('F1-Score')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Inicializar visualizador\n",
    "visualizer = AdvancedVisualizer(config)\n",
    "print(\"‚úÖ Sistema de visualizaci√≥n avanzada configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de Procesamiento de Video Avanzado\n",
    "class AdvancedVideoProcessor:\n",
    "    \"\"\"Sistema avanzado de procesamiento de video con threading y optimizaciones GPU\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config, model_path: str = None):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        self.detection_data = []\n",
    "        self.frame_queue = queue.Queue(maxsize=10)\n",
    "        self.result_queue = queue.Queue(maxsize=10)\n",
    "        self.stop_processing = False\n",
    "        \n",
    "        # Configuraci√≥n de video\n",
    "        self.video_config = config.config.get('video', {})\n",
    "        self.detection_config = config.config.get('detection', {})\n",
    "        \n",
    "        # Inicializar modelo\n",
    "        if model_path and Path(model_path).exists():\n",
    "            self.load_model(model_path)\n",
    "        else:\n",
    "            self.load_default_model()\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Carga el modelo YOLOv8 entrenado\"\"\"\n",
    "        try:\n",
    "            self.model = YOLO(model_path)\n",
    "            config.logger.info(f\"Modelo cargado desde: {model_path}\")\n",
    "        except Exception as e:\n",
    "            config.logger.error(f\"Error cargando modelo: {e}\")\n",
    "            self.load_default_model()\n",
    "    \n",
    "    def load_default_model(self):\n",
    "        \"\"\"Carga el modelo YOLOv8 preentrenado por defecto\"\"\"\n",
    "        try:\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "            config.logger.info(\"Modelo YOLOv8n preentrenado cargado\")\n",
    "        except Exception as e:\n",
    "            config.logger.error(f\"Error cargando modelo por defecto: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def setup_device(self):\n",
    "        \"\"\"Configura el dispositivo de procesamiento (GPU/CPU)\"\"\"\n",
    "        device_config = self.detection_config.get('device', 'auto')\n",
    "        \n",
    "        if device_config == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                device = 'cuda'\n",
    "                config.logger.info(f\"Usando GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            else:\n",
    "                device = 'cpu'\n",
    "                config.logger.info(\"Usando CPU\")\n",
    "        else:\n",
    "            device = device_config\n",
    "            config.logger.info(f\"Dispositivo configurado: {device}\")\n",
    "        \n",
    "        return device\n",
    "    \n",
    "    def preprocess_frame(self, frame: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Preprocesa el frame para optimizar el procesamiento\"\"\"\n",
    "        # Redimensionar si es necesario\n",
    "        max_resolution = self.video_config.get('max_resolution', 1920)\n",
    "        downsample_threshold = self.video_config.get('downsample_threshold', 1080)\n",
    "        \n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        if height > downsample_threshold or width > downsample_threshold:\n",
    "            # Calcular nueva resoluci√≥n manteniendo aspect ratio\n",
    "            scale = min(max_resolution / width, max_resolution / height)\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            \n",
    "            frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "            config.logger.debug(f\"Frame redimensionado: {width}x{height} -> {new_width}x{new_height}\")\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def detect_objects(self, frame: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Detecta objetos en el frame usando YOLOv8\"\"\"\n",
    "        if not self.model:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Realizar detecci√≥n\n",
    "            results = self.model(\n",
    "                frame,\n",
    "                conf=self.detection_config.get('conf_threshold', 0.5),\n",
    "                iou=self.detection_config.get('iou_threshold', 0.4),\n",
    "                max_det=self.detection_config.get('max_detections', 10),\n",
    "                device=self.setup_device(),\n",
    "                half=True if torch.cuda.is_available() else False\n",
    "            )\n",
    "            \n",
    "            detections = []\n",
    "            for result in results:\n",
    "                if result.boxes is not None:\n",
    "                    boxes = result.boxes.xyxy.cpu().numpy()\n",
    "                    confidences = result.boxes.conf.cpu().numpy()\n",
    "                    class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "                    \n",
    "                    for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):\n",
    "                        # Convertir formato de bbox (xyxy -> xywh)\n",
    "                        x1, y1, x2, y2 = box\n",
    "                        w, h = x2 - x1, y2 - y1\n",
    "                        \n",
    "                        detection = {\n",
    "                            'bbox': [float(x1), float(y1), float(w), float(h)],\n",
    "                            'confidence': float(conf),\n",
    "                            'class_id': int(class_id),\n",
    "                            'class_name': list(CLASSES.keys())[class_id] if class_id < len(CLASSES) else 'unknown'\n",
    "                        }\n",
    "                        detections.append(detection)\n",
    "            \n",
    "            return detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            config.logger.error(f\"Error en detecci√≥n: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def process_detection(self, detection: Dict, frame: np.ndarray, frame_number: int) -> Dict:\n",
    "        \"\"\"Procesa una detecci√≥n individual con clasificaci√≥n avanzada\"\"\"\n",
    "        bbox = detection['bbox']\n",
    "        class_name = detection['class_name']\n",
    "        \n",
    "        # Clasificar tama√±o\n",
    "        size = classifier.classify_size(bbox, frame.shape[:2])\n",
    "        \n",
    "        # Clasificar color\n",
    "        color = classifier.classify_color(frame, bbox)\n",
    "        \n",
    "        # Extraer detalles espec√≠ficos\n",
    "        details = classifier.extract_details(frame, bbox, class_name)\n",
    "        \n",
    "        # Estimar velocidad (usando frame_number como track_id temporal)\n",
    "        speed = classifier.estimate_speed(frame_number, bbox, frame_number)\n",
    "        \n",
    "        # Crear metadata completa\n",
    "        processed_detection = {\n",
    "            'frame_number': frame_number,\n",
    "            'timestamp': frame_number / 30.0,  # Asumiendo 30 FPS\n",
    "            'bbox': bbox,\n",
    "            'class_name': class_name,\n",
    "            'subclass': self._determine_subclass(class_name, details),\n",
    "            'size': size,\n",
    "            'color': color,\n",
    "            'details': details,\n",
    "            'confidence': detection['confidence'],\n",
    "            'speed': speed,\n",
    "            'orientation': details.get('orientation_angle', 0),\n",
    "            'brightness': self._calculate_brightness(frame, bbox)\n",
    "        }\n",
    "        \n",
    "        return processed_detection\n",
    "    \n",
    "    def _determine_subclass(self, class_name: str, details: Dict) -> str:\n",
    "        \"\"\"Determina la subclase basada en detalles espec√≠ficos\"\"\"\n",
    "        if class_name == 'persona':\n",
    "            # Determinar si es peat√≥n o ciclista basado en pose\n",
    "            if details.get('pose_landmarks', 0) > 20:\n",
    "                return 'peaton'\n",
    "            else:\n",
    "                return 'ciclista'\n",
    "        \n",
    "        elif class_name == 'carro':\n",
    "            # Determinar tipo de veh√≠culo basado en forma y ruedas\n",
    "            wheels = details.get('wheels_detected', 0)\n",
    "            if wheels >= 6:\n",
    "                return 'camion'\n",
    "            elif wheels >= 4:\n",
    "                return 'sedan'\n",
    "            else:\n",
    "                return 'suv'\n",
    "        \n",
    "        elif class_name == 'senal_trafico':\n",
    "            # Determinar tipo de se√±al basado en OCR\n",
    "            ocr_text = details.get('ocr_text', '').lower()\n",
    "            if 'stop' in ocr_text or 'alto' in ocr_text:\n",
    "                return 'stop'\n",
    "            elif 'yield' in ocr_text or 'ceda' in ocr_text:\n",
    "                return 'yield'\n",
    "            elif any(char.isdigit() for char in ocr_text):\n",
    "                return 'velocidad'\n",
    "            else:\n",
    "                return 'direccion'\n",
    "        \n",
    "        elif class_name == 'moto':\n",
    "            # Determinar tipo de moto basado en forma\n",
    "            orientation = abs(details.get('orientation_angle', 0))\n",
    "            if orientation > 45:\n",
    "                return 'deportiva'\n",
    "            else:\n",
    "                return 'clasica'\n",
    "        \n",
    "        return 'unknown'\n",
    "    \n",
    "    def _calculate_brightness(self, frame: np.ndarray, bbox: List[float]) -> float:\n",
    "        \"\"\"Calcula el brillo promedio del ROI\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        \n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        if roi.size == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Convertir a escala de grises y calcular brillo promedio\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        brightness = np.mean(gray_roi) / 255.0\n",
    "        \n",
    "        return float(brightness)\n",
    "    \n",
    "    def anonymize_faces(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:\n",
    "        \"\"\"Anonimiza caras en detecciones de personas\"\"\"\n",
    "        anonymized_frame = frame.copy()\n",
    "        \n",
    "        for detection in detections:\n",
    "            if detection['class_name'] == 'persona':\n",
    "                bbox = detection['bbox']\n",
    "                x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "                \n",
    "                # Aplicar blur gaussiano para anonimizar\n",
    "                roi = anonymized_frame[y:y+h, x:x+w]\n",
    "                if roi.size > 0:\n",
    "                    blurred_roi = cv2.GaussianBlur(roi, (99, 99), 30)\n",
    "                    anonymized_frame[y:y+h, x:x+w] = blurred_roi\n",
    "        \n",
    "        return anonymized_frame\n",
    "    \n",
    "    def draw_detections(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:\n",
    "        \"\"\"Dibuja las detecciones en el frame\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        for detection in detections:\n",
    "            bbox = detection['bbox']\n",
    "            x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            \n",
    "            # Color del bbox basado en confianza\n",
    "            conf = detection['confidence']\n",
    "            if conf > 0.8:\n",
    "                color = (0, 255, 0)  # Verde\n",
    "            elif conf > 0.5:\n",
    "                color = (0, 255, 255)  # Amarillo\n",
    "            else:\n",
    "                color = (0, 0, 255)  # Rojo\n",
    "            \n",
    "            # Dibujar bbox\n",
    "            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "            # Crear label\n",
    "            label = f\"{detection['class_name']} {detection['subclass']}\"\n",
    "            label += f\" {detection['size']} {detection['color']}\"\n",
    "            if detection['details']:\n",
    "                details_str = ', '.join([f\"{k}:{v}\" for k, v in detection['details'].items() if v])\n",
    "                if details_str:\n",
    "                    label += f\" ({details_str})\"\n",
    "            label += f\" {conf:.2f}\"\n",
    "            \n",
    "            # Dibujar label\n",
    "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "            cv2.rectangle(annotated_frame, (x, y - label_size[1] - 10), \n",
    "                         (x + label_size[0], y), color, -1)\n",
    "            cv2.putText(annotated_frame, label, (x, y - 5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        return annotated_frame\n",
    "\n",
    "# Inicializar procesador de video\n",
    "video_processor = AdvancedVideoProcessor(config)\n",
    "print(\"‚úÖ Pipeline de procesamiento de video configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977706e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de Guardado Jer√°rquico y Metadata\n",
    "class AdvancedDataManager:\n",
    "    \"\"\"Sistema avanzado de guardado jer√°rquico con metadata completa\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.base_dir = Path(config.config['output']['base_dir'])\n",
    "        self.detections_dir = self.base_dir / 'detecciones'\n",
    "        self.videos_dir = self.base_dir / 'videos_procesados'\n",
    "        self.logs_dir = self.base_dir / 'logs'\n",
    "        \n",
    "        # Crear estructura de directorios\n",
    "        self._create_directory_structure()\n",
    "        \n",
    "        # Contador de detecciones\n",
    "        self.detection_count = 0\n",
    "        self.detection_data = []\n",
    "    \n",
    "    def _create_directory_structure(self):\n",
    "        \"\"\"Crea la estructura jer√°rquica de directorios\"\"\"\n",
    "        # Directorios principales\n",
    "        for category in CLASSES.keys():\n",
    "            category_dir = self.detections_dir / category\n",
    "            category_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Subdirectorios por subclase\n",
    "            for subclass in CLASSES[category]:\n",
    "                subclass_dir = category_dir / subclass\n",
    "                subclass_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Subdirectorios por tama√±o y color\n",
    "                sizes = ['peque√±o', 'mediano', 'grande']\n",
    "                colors = ['rojo', 'azul', 'verde', 'amarillo', 'naranja', 'morado', 'rosa', 'gris']\n",
    "                \n",
    "                for size in sizes:\n",
    "                    for color in colors:\n",
    "                        size_color_dir = subclass_dir / f\"{size}_{color}\"\n",
    "                        size_color_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Directorios adicionales\n",
    "        self.videos_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        config.logger.info(f\"Estructura de directorios creada en: {self.base_dir}\")\n",
    "    \n",
    "    def save_detection(self, detection: Dict, frame: np.ndarray, frame_number: int) -> str:\n",
    "        \"\"\"Guarda una detecci√≥n individual con su imagen y metadata\"\"\"\n",
    "        try:\n",
    "            # Extraer informaci√≥n de la detecci√≥n\n",
    "            class_name = detection['class_name']\n",
    "            subclass = detection['subclass']\n",
    "            size = detection['size']\n",
    "            color = detection['color']\n",
    "            \n",
    "            # Crear nombre de archivo √∫nico\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"{class_name}_{subclass}_{size}_{color}_{frame_number:06d}_{timestamp}\"\n",
    "            \n",
    "            # Ruta de guardado\n",
    "            save_dir = (self.detections_dir / class_name / subclass / f\"{size}_{color}\")\n",
    "            image_path = save_dir / f\"{filename}.jpg\"\n",
    "            json_path = save_dir / f\"{filename}.json\"\n",
    "            \n",
    "            # Extraer ROI del frame\n",
    "            bbox = detection['bbox']\n",
    "            x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            if roi.size == 0:\n",
    "                config.logger.warning(f\"ROI vac√≠o para detecci√≥n en frame {frame_number}\")\n",
    "                return None\n",
    "            \n",
    "            # Guardar imagen\n",
    "            cv2.imwrite(str(image_path), roi)\n",
    "            \n",
    "            # Preparar metadata\n",
    "            metadata = {\n",
    "                'frame_number': frame_number,\n",
    "                'timestamp': detection['timestamp'],\n",
    "                'bbox': bbox,\n",
    "                'class_name': class_name,\n",
    "                'subclass': subclass,\n",
    "                'size': size,\n",
    "                'color': color,\n",
    "                'details': detection['details'],\n",
    "                'confidence': detection['confidence'],\n",
    "                'speed': detection['speed'],\n",
    "                'orientation': detection['orientation'],\n",
    "                'brightness': detection['brightness'],\n",
    "                'image_path': str(image_path.relative_to(self.base_dir)),\n",
    "                'created_at': datetime.now().isoformat(),\n",
    "                'model_version': 'yolov8_advanced',\n",
    "                'processing_info': {\n",
    "                    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                    'augmentation_applied': False,\n",
    "                    'preprocessing_steps': ['resize', 'normalize']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Guardar metadata\n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            # Agregar a datos de detecci√≥n\n",
    "            self.detection_data.append(metadata)\n",
    "            self.detection_count += 1\n",
    "            \n",
    "            config.logger.debug(f\"Detecci√≥n guardada: {image_path}\")\n",
    "            return str(image_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            config.logger.error(f\"Error guardando detecci√≥n: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_processed_video(self, video_path: str, output_frames: List[np.ndarray], \n",
    "                           fps: float, resolution: Tuple[int, int]) -> str:\n",
    "        \"\"\"Guarda el video procesado\"\"\"\n",
    "        try:\n",
    "            # Crear nombre de archivo de salida\n",
    "            input_name = Path(video_path).stem\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_filename = f\"{input_name}_procesado_{timestamp}.mp4\"\n",
    "            output_path = self.videos_dir / output_filename\n",
    "            \n",
    "            # Configurar VideoWriter\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            height, width = resolution\n",
    "            \n",
    "            out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "            \n",
    "            # Escribir frames\n",
    "            for frame in output_frames:\n",
    "                out.write(frame)\n",
    "            \n",
    "            out.release()\n",
    "            \n",
    "            config.logger.info(f\"Video procesado guardado: {output_path}\")\n",
    "            return str(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            config.logger.error(f\"Error guardando video: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_summary_report(self) -> Dict:\n",
    "        \"\"\"Genera un reporte resumen de todas las detecciones\"\"\"\n",
    "        if not self.detection_data:\n",
    "            return {}\n",
    "        \n",
    "        # Estad√≠sticas generales\n",
    "        total_detections = len(self.detection_data)\n",
    "        \n",
    "        # Estad√≠sticas por clase\n",
    "        class_stats = {}\n",
    "        for detection in self.detection_data:\n",
    "            class_name = detection['class_name']\n",
    "            if class_name not in class_stats:\n",
    "                class_stats[class_name] = {\n",
    "                    'count': 0,\n",
    "                    'avg_confidence': 0,\n",
    "                    'sizes': {'peque√±o': 0, 'mediano': 0, 'grande': 0},\n",
    "                    'colors': {},\n",
    "                    'subclasses': {}\n",
    "                }\n",
    "            \n",
    "            stats = class_stats[class_name]\n",
    "            stats['count'] += 1\n",
    "            stats['avg_confidence'] += detection['confidence']\n",
    "            \n",
    "            # Contar tama√±os\n",
    "            size = detection['size']\n",
    "            if size in stats['sizes']:\n",
    "                stats['sizes'][size] += 1\n",
    "            \n",
    "            # Contar colores\n",
    "            color = detection['color']\n",
    "            stats['colors'][color] = stats['colors'].get(color, 0) + 1\n",
    "            \n",
    "            # Contar subclases\n",
    "            subclass = detection['subclass']\n",
    "            stats['subclasses'][subclass] = stats['subclasses'].get(subclass, 0) + 1\n",
    "        \n",
    "        # Calcular promedios\n",
    "        for class_name in class_stats:\n",
    "            stats = class_stats[class_name]\n",
    "            stats['avg_confidence'] /= stats['count']\n",
    "        \n",
    "        # Crear reporte\n",
    "        report = {\n",
    "            'summary': {\n",
    "                'total_detections': total_detections,\n",
    "                'unique_classes': len(class_stats),\n",
    "                'processing_date': datetime.now().isoformat(),\n",
    "                'model_version': 'yolov8_advanced'\n",
    "            },\n",
    "            'class_statistics': class_stats,\n",
    "            'performance_metrics': {\n",
    "                'avg_confidence_overall': np.mean([d['confidence'] for d in self.detection_data]),\n",
    "                'confidence_std': np.std([d['confidence'] for d in self.detection_data]),\n",
    "                'avg_speed': np.mean([d['speed'] for d in self.detection_data]),\n",
    "                'avg_brightness': np.mean([d['brightness'] for d in self.detection_data])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Guardar reporte\n",
    "        report_path = self.logs_dir / f\"reporte_detecciones_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        config.logger.info(f\"Reporte generado: {report_path}\")\n",
    "        return report\n",
    "    \n",
    "    def export_to_csv(self) -> str:\n",
    "        \"\"\"Exporta todas las detecciones a CSV\"\"\"\n",
    "        if not self.detection_data:\n",
    "            return None\n",
    "        \n",
    "        # Crear DataFrame\n",
    "        df_data = []\n",
    "        for detection in self.detection_data:\n",
    "            row = {\n",
    "                'frame_number': detection['frame_number'],\n",
    "                'timestamp': detection['timestamp'],\n",
    "                'class_name': detection['class_name'],\n",
    "                'subclass': detection['subclass'],\n",
    "                'size': detection['size'],\n",
    "                'color': detection['color'],\n",
    "                'confidence': detection['confidence'],\n",
    "                'speed': detection['speed'],\n",
    "                'orientation': detection['orientation'],\n",
    "                'brightness': detection['brightness'],\n",
    "                'bbox_x': detection['bbox'][0],\n",
    "                'bbox_y': detection['bbox'][1],\n",
    "                'bbox_w': detection['bbox'][2],\n",
    "                'bbox_h': detection['bbox'][3]\n",
    "            }\n",
    "            \n",
    "            # Agregar detalles espec√≠ficos\n",
    "            for key, value in detection['details'].items():\n",
    "                row[f'detail_{key}'] = value\n",
    "            \n",
    "            df_data.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(df_data)\n",
    "        \n",
    "        # Guardar CSV\n",
    "        csv_path = self.logs_dir / f\"detecciones_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        config.logger.info(f\"Datos exportados a CSV: {csv_path}\")\n",
    "        return str(csv_path)\n",
    "\n",
    "# Inicializar gestor de datos\n",
    "data_manager = AdvancedDataManager(config)\n",
    "print(\"‚úÖ Sistema de guardado jer√°rquico configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n Principal de Procesamiento de Video\n",
    "def process_video_complete(video_path: str, model_path: str = None, \n",
    "                          show_preview: bool = False, save_detections: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para procesar un video completo con detecci√≥n y clasificaci√≥n avanzada\n",
    "    \n",
    "    Args:\n",
    "        video_path: Ruta al video de entrada\n",
    "        model_path: Ruta al modelo entrenado (opcional)\n",
    "        show_preview: Mostrar preview del procesamiento\n",
    "        save_detections: Guardar detecciones individuales\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario con estad√≠sticas del procesamiento\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializar procesador de video\n",
    "    processor = AdvancedVideoProcessor(config, model_path)\n",
    "    \n",
    "    # Abrir video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        config.logger.error(f\"No se pudo abrir el video: {video_path}\")\n",
    "        return {}\n",
    "    \n",
    "    # Obtener propiedades del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    config.logger.info(f\"Procesando video: {video_path}\")\n",
    "    config.logger.info(f\"Resoluci√≥n: {width}x{height}, FPS: {fps}, Frames: {total_frames}\")\n",
    "    \n",
    "    # Variables de procesamiento\n",
    "    frame_number = 0\n",
    "    processed_frames = []\n",
    "    all_detections = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Barra de progreso\n",
    "    pbar = tqdm(total=total_frames, desc=\"Procesando video\", unit=\"frames\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Preprocesar frame\n",
    "            processed_frame = processor.preprocess_frame(frame)\n",
    "            \n",
    "            # Detectar objetos\n",
    "            detections = processor.detect_objects(processed_frame)\n",
    "            \n",
    "            # Procesar cada detecci√≥n\n",
    "            processed_detections = []\n",
    "            for detection in detections:\n",
    "                processed_detection = processor.process_detection(\n",
    "                    detection, processed_frame, frame_number\n",
    "                )\n",
    "                processed_detections.append(processed_detection)\n",
    "                \n",
    "                # Guardar detecci√≥n si est√° habilitado\n",
    "                if save_detections:\n",
    "                    data_manager.save_detection(\n",
    "                        processed_detection, processed_frame, frame_number\n",
    "                    )\n",
    "            \n",
    "            # Anonimizar caras si es necesario\n",
    "            if config.config.get('privacy', {}).get('anonymize_faces', False):\n",
    "                processed_frame = processor.anonymize_faces(processed_frame, processed_detections)\n",
    "            \n",
    "            # Dibujar detecciones\n",
    "            annotated_frame = processor.draw_detections(processed_frame, processed_detections)\n",
    "            \n",
    "            # Agregar informaci√≥n del frame\n",
    "            info_text = f\"Frame: {frame_number}/{total_frames} | FPS: {fps:.1f} | Detecciones: {len(processed_detections)}\"\n",
    "            cv2.putText(annotated_frame, info_text, (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Mostrar preview si est√° habilitado\n",
    "            if show_preview:\n",
    "                cv2.imshow('Procesamiento en Tiempo Real', annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            # Guardar frame procesado\n",
    "            processed_frames.append(annotated_frame)\n",
    "            all_detections.extend(processed_detections)\n",
    "            \n",
    "            frame_number += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Limpiar memoria cada 50 frames\n",
    "            if frame_number % 50 == 0:\n",
    "                gc.collect()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        config.logger.info(\"Procesamiento interrumpido por el usuario\")\n",
    "    \n",
    "    finally:\n",
    "        # Limpiar recursos\n",
    "        cap.release()\n",
    "        if show_preview:\n",
    "            cv2.destroyAllWindows()\n",
    "        pbar.close()\n",
    "    \n",
    "    # Calcular estad√≠sticas\n",
    "    processing_time = time.time() - start_time\n",
    "    avg_fps = frame_number / processing_time if processing_time > 0 else 0\n",
    "    \n",
    "    # Guardar video procesado\n",
    "    video_output_path = None\n",
    "    if processed_frames:\n",
    "        video_output_path = data_manager.save_processed_video(\n",
    "            video_path, processed_frames, fps, (width, height)\n",
    "        )\n",
    "    \n",
    "    # Generar reportes\n",
    "    summary_report = data_manager.generate_summary_report()\n",
    "    csv_path = data_manager.export_to_csv()\n",
    "    \n",
    "    # Estad√≠sticas finales\n",
    "    stats = {\n",
    "        'video_path': video_path,\n",
    "        'total_frames': frame_number,\n",
    "        'total_detections': len(all_detections),\n",
    "        'processing_time': processing_time,\n",
    "        'avg_fps': avg_fps,\n",
    "        'video_output_path': video_output_path,\n",
    "        'csv_path': csv_path,\n",
    "        'summary_report': summary_report,\n",
    "        'detections_per_frame': len(all_detections) / frame_number if frame_number > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Imprimir resumen\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESAMIENTO COMPLETADO\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Video procesado: {frame_number} frames\")\n",
    "    print(f\"Detecciones totales: {len(all_detections)}\")\n",
    "    print(f\"Tiempo de procesamiento: {processing_time:.2f} segundos\")\n",
    "    print(f\"FPS promedio: {avg_fps:.2f}\")\n",
    "    print(f\"Video guardado en: {video_output_path}\")\n",
    "    print(f\"Reporte CSV: {csv_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Funci√≥n para entrenar modelo\n",
    "def train_model_complete(dataset_path: str, use_optimization: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Funci√≥n completa para entrenar el modelo YOLOv8\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Ruta al dataset de entrenamiento\n",
    "        use_optimization: Usar optimizaci√≥n de hiperpar√°metros\n",
    "    \n",
    "    Returns:\n",
    "        Ruta al modelo entrenado\n",
    "    \"\"\"\n",
    "    \n",
    "    config.logger.info(\"Iniciando entrenamiento completo del modelo...\")\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    success = trainer.train_model(dataset_path, use_optimization)\n",
    "    \n",
    "    if success and trainer.best_model_path:\n",
    "        # Evaluar modelo\n",
    "        metrics = trainer.evaluate_model(dataset_path)\n",
    "        \n",
    "        # Crear visualizaciones\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # An√°lisis de confianza\n",
    "        confidence_path = visualizer.output_dir / f\"confidence_analysis_{timestamp}.png\"\n",
    "        visualizer.create_confidence_analysis(trainer.training_results, str(confidence_path))\n",
    "        \n",
    "        # An√°lisis de regresi√≥n 3D\n",
    "        regression_path = visualizer.output_dir / f\"regression_3d_{timestamp}.png\"\n",
    "        visualizer.create_3d_regression_analysis([], str(regression_path))\n",
    "        \n",
    "        # Heatmap de correlaciones\n",
    "        correlation_path = visualizer.output_dir / f\"correlation_heatmap_{timestamp}.png\"\n",
    "        visualizer.create_correlation_heatmap([], str(correlation_path))\n",
    "        \n",
    "        # Curvas de aprendizaje\n",
    "        learning_path = visualizer.output_dir / f\"learning_curves_{timestamp}.png\"\n",
    "        visualizer.create_learning_curves(trainer.training_results, str(learning_path))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ENTRENAMIENTO COMPLETADO\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Modelo guardado en: {trainer.best_model_path}\")\n",
    "        print(f\"M√©tricas de evaluaci√≥n: {metrics}\")\n",
    "        print(f\"Visualizaciones guardadas en: {visualizer.output_dir}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        return str(trainer.best_model_path)\n",
    "    \n",
    "    else:\n",
    "        config.logger.error(\"Error en el entrenamiento del modelo\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Funciones principales configuradas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f19e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento del Video DJI - Calle\n",
    "print(\"üéØ SISTEMA AVANZADO DE DETECCI√ìN Y CLASIFICACI√ìN DE OBJETOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar que el video existe\n",
    "video_path = \"calle-dji.MOV\"  # Video del drone DJI\n",
    "if Path(video_path).exists():\n",
    "    print(f\"‚úÖ Video encontrado: {video_path}\")\n",
    "    \n",
    "    # Obtener informaci√≥n del video antes del procesamiento\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"üìπ Informaci√≥n del video:\")\n",
    "    print(f\"   ‚Ä¢ Resoluci√≥n: {width}x{height}\")\n",
    "    print(f\"   ‚Ä¢ FPS: {fps:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Frames totales: {total_frames}\")\n",
    "    print(f\"   ‚Ä¢ Duraci√≥n: {duration:.1f} segundos\")\n",
    "    \n",
    "    # Procesar video con el sistema completo\n",
    "    print(\"\\nüöÄ Iniciando procesamiento del video...\")\n",
    "    \n",
    "    # Configurar par√°metros de procesamiento\n",
    "    show_preview = False  # Cambiar a True para ver preview en tiempo real\n",
    "    save_detections = True  # Guardar detecciones individuales\n",
    "    \n",
    "    # Procesar video\n",
    "    stats = process_video_complete(\n",
    "        video_path=video_path,\n",
    "        model_path=None,  # Usar modelo preentrenado\n",
    "        show_preview=show_preview,\n",
    "        save_detections=save_detections\n",
    "    )\n",
    "    \n",
    "    if stats:\n",
    "        print(f\"\\nüìä ESTAD√çSTICAS DEL PROCESAMIENTO:\")\n",
    "        print(f\"   ‚Ä¢ Frames procesados: {stats['total_frames']}\")\n",
    "        print(f\"   ‚Ä¢ Detecciones totales: {stats['total_detections']}\")\n",
    "        print(f\"   ‚Ä¢ Tiempo de procesamiento: {stats['processing_time']:.2f} segundos\")\n",
    "        print(f\"   ‚Ä¢ FPS promedio: {stats['avg_fps']:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Detecciones por frame: {stats['detections_per_frame']:.2f}\")\n",
    "        \n",
    "        if stats['video_output_path']:\n",
    "            print(f\"   ‚Ä¢ Video procesado (MP4): {stats['video_output_path']}\")\n",
    "        \n",
    "        if stats['csv_path']:\n",
    "            print(f\"   ‚Ä¢ Datos CSV: {stats['csv_path']}\")\n",
    "        \n",
    "        # Mostrar resumen de detecciones por clase\n",
    "        if stats['summary_report'] and 'class_statistics' in stats['summary_report']:\n",
    "            print(f\"\\nüìà DETECCIONES POR CLASE:\")\n",
    "            for class_name, class_stats in stats['summary_report']['class_statistics'].items():\n",
    "                print(f\"   ‚Ä¢ {class_name}: {class_stats['count']} detecciones (confianza avg: {class_stats['avg_confidence']:.3f})\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Video no encontrado: {video_path}\")\n",
    "    print(\"   Aseg√∫rate de que el archivo 'calle-dji.MOV' est√© en el directorio actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1703e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demostraci√≥n de Visualizaciones Avanzadas\n",
    "print(\"\\nüìà CREANDO VISUALIZACIONES AVANZADAS...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear visualizaciones de demostraci√≥n\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 1. An√°lisis de confianza\n",
    "print(\"1. Generando an√°lisis de confianza...\")\n",
    "confidence_path = visualizer.output_dir / f\"demo_confidence_analysis_{timestamp}.png\"\n",
    "visualizer.create_confidence_analysis(None, str(confidence_path))\n",
    "\n",
    "# 2. An√°lisis de regresi√≥n 3D\n",
    "print(\"2. Generando an√°lisis de regresi√≥n 3D...\")\n",
    "regression_path = visualizer.output_dir / f\"demo_regression_3d_{timestamp}.png\"\n",
    "model, r2, mse = visualizer.create_3d_regression_analysis([], str(regression_path))\n",
    "\n",
    "# 3. Heatmap de correlaciones\n",
    "print(\"3. Generando heatmap de correlaciones...\")\n",
    "correlation_path = visualizer.output_dir / f\"demo_correlation_heatmap_{timestamp}.png\"\n",
    "correlation_matrix = visualizer.create_correlation_heatmap([], str(correlation_path))\n",
    "\n",
    "# 4. Curvas de aprendizaje\n",
    "print(\"4. Generando curvas de aprendizaje...\")\n",
    "learning_path = visualizer.output_dir / f\"demo_learning_curves_{timestamp}.png\"\n",
    "visualizer.create_learning_curves(None, str(learning_path))\n",
    "\n",
    "print(f\"\\n‚úÖ Visualizaciones guardadas en: {visualizer.output_dir}\")\n",
    "print(\"   ‚Ä¢ An√°lisis de confianza\")\n",
    "print(\"   ‚Ä¢ Regresi√≥n lineal m√∫ltiple 3D\")\n",
    "print(\"   ‚Ä¢ Heatmap de correlaciones\")\n",
    "print(\"   ‚Ä¢ Curvas de aprendizaje\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba del Sistema - Procesamiento del Video DJI\n",
    "print(\"üéØ INICIANDO PROCESAMIENTO DEL VIDEO DJI\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Verificar que el video existe\n",
    "video_path = \"calle-dji.MOV\"\n",
    "if Path(video_path).exists():\n",
    "    print(f\"‚úÖ Video encontrado: {video_path}\")\n",
    "    \n",
    "    # Obtener informaci√≥n del video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"üìπ Informaci√≥n del video:\")\n",
    "    print(f\"   ‚Ä¢ Resoluci√≥n: {width}x{height}\")\n",
    "    print(f\"   ‚Ä¢ FPS: {fps:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Frames totales: {total_frames}\")\n",
    "    print(f\"   ‚Ä¢ Duraci√≥n: {duration:.1f} segundos\")\n",
    "    \n",
    "    # Procesar solo los primeros 100 frames para prueba\n",
    "    print(f\"\\nüöÄ Procesando primeros 100 frames como prueba...\")\n",
    "    \n",
    "    # Inicializar procesador\n",
    "    processor = AdvancedVideoProcessor(config)\n",
    "    \n",
    "    # Abrir video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_number = 0\n",
    "    detections_count = 0\n",
    "    \n",
    "    # Procesar frames\n",
    "    with tqdm(total=min(100, total_frames), desc=\"Procesando frames\") as pbar:\n",
    "        while frame_number < 100:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Preprocesar frame\n",
    "            processed_frame = processor.preprocess_frame(frame)\n",
    "            \n",
    "            # Detectar objetos\n",
    "            detections = processor.detect_objects(processed_frame)\n",
    "            \n",
    "            # Procesar cada detecci√≥n\n",
    "            for detection in detections:\n",
    "                processed_detection = processor.process_detection(\n",
    "                    detection, processed_frame, frame_number\n",
    "                )\n",
    "                \n",
    "                # Guardar detecci√≥n\n",
    "                data_manager.save_detection(\n",
    "                    processed_detection, processed_frame, frame_number\n",
    "                )\n",
    "                detections_count += 1\n",
    "            \n",
    "            frame_number += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADOS DE LA PRUEBA:\")\n",
    "    print(f\"   ‚Ä¢ Frames procesados: {frame_number}\")\n",
    "    print(f\"   ‚Ä¢ Detecciones encontradas: {detections_count}\")\n",
    "    print(f\"   ‚Ä¢ Promedio detecciones/frame: {detections_count/frame_number:.2f}\")\n",
    "    \n",
    "    # Generar reporte\n",
    "    summary_report = data_manager.generate_summary_report()\n",
    "    csv_path = data_manager.export_to_csv()\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Reporte generado: {csv_path}\")\n",
    "    print(f\"   ‚Ä¢ Detecciones guardadas en: {data_manager.detections_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Video no encontrado: {video_path}\")\n",
    "    print(\"   Aseg√∫rate de que el archivo 'calle-dji.MOV' est√© en el directorio actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e178eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento Optimizado del Video DJI (Sin Logs Excesivos)\n",
    "print(\"üéØ PROCESAMIENTO OPTIMIZADO DEL VIDEO DJI\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configurar logging para reducir output\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)  # Solo errores cr√≠ticos\n",
    "\n",
    "# Verificar que el video existe\n",
    "video_path = \"calle-dji.MOV\"\n",
    "if Path(video_path).exists():\n",
    "    print(f\"‚úÖ Video encontrado: {video_path}\")\n",
    "    \n",
    "    # Obtener informaci√≥n del video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"üìπ Informaci√≥n del video:\")\n",
    "    print(f\"   ‚Ä¢ Resoluci√≥n: {width}x{height}\")\n",
    "    print(f\"   ‚Ä¢ FPS: {fps:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Frames totales: {total_frames}\")\n",
    "    print(f\"   ‚Ä¢ Duraci√≥n: {duration:.1f} segundos\")\n",
    "    \n",
    "    # Procesar video completo con progreso optimizado\n",
    "    print(f\"\\nüöÄ Procesando video completo...\")\n",
    "    \n",
    "    # Inicializar procesador\n",
    "    processor = AdvancedVideoProcessor(config)\n",
    "    \n",
    "    # Abrir video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_number = 0\n",
    "    detections_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Procesar frames con progreso optimizado\n",
    "    with tqdm(total=total_frames, desc=\"Procesando video\", unit=\"frames\", \n",
    "              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Preprocesar frame\n",
    "            processed_frame = processor.preprocess_frame(frame)\n",
    "            \n",
    "            # Detectar objetos\n",
    "            detections = processor.detect_objects(processed_frame)\n",
    "            \n",
    "            # Procesar cada detecci√≥n\n",
    "            for detection in detections:\n",
    "                processed_detection = processor.process_detection(\n",
    "                    detection, processed_frame, frame_number\n",
    "                )\n",
    "                \n",
    "                # Guardar detecci√≥n\n",
    "                data_manager.save_detection(\n",
    "                    processed_detection, processed_frame, frame_number\n",
    "                )\n",
    "                detections_count += 1\n",
    "            \n",
    "            frame_number += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Mostrar estad√≠sticas cada 100 frames\n",
    "            if frame_number % 100 == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                fps_current = frame_number / elapsed_time\n",
    "                pbar.set_postfix({\n",
    "                    'Detecciones': detections_count,\n",
    "                    'FPS': f'{fps_current:.1f}',\n",
    "                    'Detecciones/frame': f'{detections_count/frame_number:.2f}'\n",
    "                })\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Calcular estad√≠sticas finales\n",
    "    total_time = time.time() - start_time\n",
    "    avg_fps = frame_number / total_time if total_time > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADOS DEL PROCESAMIENTO:\")\n",
    "    print(f\"   ‚Ä¢ Frames procesados: {frame_number}\")\n",
    "    print(f\"   ‚Ä¢ Detecciones encontradas: {detections_count}\")\n",
    "    print(f\"   ‚Ä¢ Tiempo total: {total_time:.1f} segundos\")\n",
    "    print(f\"   ‚Ä¢ FPS promedio: {avg_fps:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Promedio detecciones/frame: {detections_count/frame_number:.2f}\")\n",
    "    \n",
    "    # Generar reporte\n",
    "    print(f\"\\nüìÑ Generando reportes...\")\n",
    "    summary_report = data_manager.generate_summary_report()\n",
    "    csv_path = data_manager.export_to_csv()\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Reporte CSV: {csv_path}\")\n",
    "    print(f\"   ‚Ä¢ Detecciones guardadas en: {data_manager.detections_dir}\")\n",
    "    \n",
    "    # Mostrar resumen por clase\n",
    "    if summary_report and 'class_statistics' in summary_report:\n",
    "        print(f\"\\nüìà DETECCIONES POR CLASE:\")\n",
    "        for class_name, class_stats in summary_report['class_statistics'].items():\n",
    "            print(f\"   ‚Ä¢ {class_name}: {class_stats['count']} detecciones\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ PROCESAMIENTO COMPLETADO EXITOSAMENTE\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Video no encontrado: {video_path}\")\n",
    "    print(\"   Aseg√∫rate de que el archivo 'calle-dji.MOV' est√© en el directorio actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cafc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detener Procesamiento Actual y Reiniciar\n",
    "print(\"üõë DETENIENDO PROCESAMIENTO ACTUAL\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Limpiar recursos\n",
    "try:\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"‚úÖ Memoria liberada\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Reiniciar logging\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "print(\"üîÑ Sistema reiniciado\")\n",
    "print(\"üí° Ejecuta la celda anterior para procesar con versi√≥n optimizada\")\n",
    "print(\"üìä La nueva versi√≥n mostrar√° solo:\")\n",
    "print(\"   ‚Ä¢ Barra de progreso limpia\")\n",
    "print(\"   ‚Ä¢ Estad√≠sticas cada 100 frames\")\n",
    "print(\"   ‚Ä¢ Sin logs excesivos\")\n",
    "print(\"   ‚Ä¢ Resultados finales detallados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72001d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento Ultra Silencioso del Video DJI\n",
    "print(\"üéØ PROCESAMIENTO ULTRA SILENCIOSO DEL VIDEO DJI\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Configurar logging completamente silencioso\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Silenciar todos los logs\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "logging.getLogger('ultralytics').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('torch').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Redirigir stdout temporalmente para YOLO\n",
    "class SuppressOutput:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        self._original_stderr = sys.stderr\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stderr.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "        sys.stderr = self._original_stderr\n",
    "\n",
    "# Verificar que el video existe\n",
    "video_path = \"calle-dji.MOV\"\n",
    "if Path(video_path).exists():\n",
    "    print(f\"‚úÖ Video encontrado: {video_path}\")\n",
    "    \n",
    "    # Obtener informaci√≥n del video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"üìπ Informaci√≥n del video:\")\n",
    "    print(f\"   ‚Ä¢ Resoluci√≥n: {width}x{height}\")\n",
    "    print(f\"   ‚Ä¢ FPS: {fps:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Frames totales: {total_frames}\")\n",
    "    print(f\"   ‚Ä¢ Duraci√≥n: {duration:.1f} segundos\")\n",
    "    \n",
    "    # Procesar video completo con progreso ultra silencioso\n",
    "    print(f\"\\nüöÄ Procesando video completo (modo silencioso)...\")\n",
    "    \n",
    "    # Inicializar procesador\n",
    "    processor = AdvancedVideoProcessor(config)\n",
    "    \n",
    "    # Abrir video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_number = 0\n",
    "    detections_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Procesar frames con progreso ultra silencioso\n",
    "    with tqdm(total=total_frames, desc=\"üé¨ Procesando video\", unit=\"frames\", \n",
    "              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]',\n",
    "              ncols=100, leave=True) as pbar:\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Preprocesar frame\n",
    "            processed_frame = processor.preprocess_frame(frame)\n",
    "            \n",
    "            # Detectar objetos con output suprimido\n",
    "            with SuppressOutput():\n",
    "                detections = processor.detect_objects(processed_frame)\n",
    "            \n",
    "            # Procesar cada detecci√≥n\n",
    "            for detection in detections:\n",
    "                processed_detection = processor.process_detection(\n",
    "                    detection, processed_frame, frame_number\n",
    "                )\n",
    "                \n",
    "                # Guardar detecci√≥n\n",
    "                data_manager.save_detection(\n",
    "                    processed_detection, processed_frame, frame_number\n",
    "                )\n",
    "                detections_count += 1\n",
    "            \n",
    "            frame_number += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Mostrar estad√≠sticas cada 50 frames (m√°s frecuente)\n",
    "            if frame_number % 50 == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                fps_current = frame_number / elapsed_time\n",
    "                pbar.set_postfix({\n",
    "                    'Detecciones': detections_count,\n",
    "                    'FPS': f'{fps_current:.1f}',\n",
    "                    'Detecciones/frame': f'{detections_count/frame_number:.2f}'\n",
    "                })\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Calcular estad√≠sticas finales\n",
    "    total_time = time.time() - start_time\n",
    "    avg_fps = frame_number / total_time if total_time > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä RESULTADOS DEL PROCESAMIENTO:\")\n",
    "    print(f\"   ‚Ä¢ Frames procesados: {frame_number}\")\n",
    "    print(f\"   ‚Ä¢ Detecciones encontradas: {detections_count}\")\n",
    "    print(f\"   ‚Ä¢ Tiempo total: {total_time:.1f} segundos\")\n",
    "    print(f\"   ‚Ä¢ FPS promedio: {avg_fps:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Promedio detecciones/frame: {detections_count/frame_number:.2f}\")\n",
    "    \n",
    "    # Generar reporte\n",
    "    print(f\"\\nüìÑ Generando reportes...\")\n",
    "    summary_report = data_manager.generate_summary_report()\n",
    "    csv_path = data_manager.export_to_csv()\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Reporte CSV: {csv_path}\")\n",
    "    print(f\"   ‚Ä¢ Detecciones guardadas en: {data_manager.detections_dir}\")\n",
    "    \n",
    "    # Mostrar resumen por clase\n",
    "    if summary_report and 'class_statistics' in summary_report:\n",
    "        print(f\"\\nüìà DETECCIONES POR CLASE:\")\n",
    "        for class_name, class_stats in summary_report['class_statistics'].items():\n",
    "            print(f\"   ‚Ä¢ {class_name}: {class_stats['count']} detecciones\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ PROCESAMIENTO COMPLETADO EXITOSAMENTE\")\n",
    "    print(f\"üéâ ¬°Video procesado sin logs molestos!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Video no encontrado: {video_path}\")\n",
    "    print(\"   Aseg√∫rate de que el archivo 'calle-dji.MOV' est√© en el directorio actual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar Completamente el Output y Reiniciar\n",
    "print(\"üßπ LIMPIEZA COMPLETA DEL SISTEMA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Limpiar recursos\n",
    "try:\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"‚úÖ Memoria liberada\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Silenciar completamente todos los logs\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Configurar logging ultra silencioso\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "logging.getLogger('ultralytics').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('torch').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('PIL').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('matplotlib').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Limpiar output de la consola\n",
    "os.system('cls' if os.name == 'nt' else 'clear')\n",
    "\n",
    "print(\"üîÑ Sistema completamente reiniciado\")\n",
    "print(\"üîá Todos los logs silenciados\")\n",
    "print(\"üí° Ejecuta la celda anterior para procesamiento ultra silencioso\")\n",
    "print(\"üìä Solo ver√°s:\")\n",
    "print(\"   ‚Ä¢ Barra de progreso limpia\")\n",
    "print(\"   ‚Ä¢ Estad√≠sticas cada 50 frames\")\n",
    "print(\"   ‚Ä¢ Resultados finales\")\n",
    "print(\"   ‚Ä¢ ¬°CERO logs molestos!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrucciones de Uso del Sistema\n",
    "print(\"üéØ SISTEMA AVANZADO DE DETECCI√ìN Y CLASIFICACI√ìN DE OBJETOS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìã CARACTER√çSTICAS IMPLEMENTADAS:\")\n",
    "print(\"‚úÖ Detecci√≥n de objetos con YOLOv8\")\n",
    "print(\"‚úÖ Clasificaci√≥n por tama√±o, color y detalles\")\n",
    "print(\"‚úÖ Sistema de guardado jer√°rquico\")\n",
    "print(\"‚úÖ An√°lisis estad√≠stico avanzado\")\n",
    "print(\"‚úÖ Procesamiento optimizado para GPU/CPU\")\n",
    "\n",
    "print(\"\\nüîß COMPONENTES PRINCIPALES:\")\n",
    "print(\"‚Ä¢ AdvancedVideoProcessor: Pipeline de procesamiento de video\")\n",
    "print(\"‚Ä¢ AdvancedClassifier: Clasificaci√≥n multi-criterio\")\n",
    "print(\"‚Ä¢ AdvancedDataManager: Guardado jer√°rquico con metadata\")\n",
    "print(\"‚Ä¢ AdvancedVisualizer: Gr√°ficos y an√°lisis estad√≠stico\")\n",
    "\n",
    "print(\"\\nüìä FUNCIONALIDADES DISPONIBLES:\")\n",
    "print(\"‚Ä¢ Detecci√≥n de personas, veh√≠culos, se√±ales de tr√°fico y motos\")\n",
    "print(\"‚Ä¢ Clasificaci√≥n por tama√±o (peque√±o, mediano, grande)\")\n",
    "print(\"‚Ä¢ Clasificaci√≥n por color dominante\")\n",
    "print(\"‚Ä¢ An√°lisis de pose para personas (si MediaPipe est√° disponible)\")\n",
    "print(\"‚Ä¢ OCR para se√±ales de tr√°fico (si Tesseract est√° disponible)\")\n",
    "print(\"‚Ä¢ Estimaci√≥n de velocidad y orientaci√≥n\")\n",
    "print(\"‚Ä¢ Guardado organizado por categor√≠a/subcategor√≠a/tama√±o/color\")\n",
    "\n",
    "print(\"\\nüöÄ C√ìMO USAR EL SISTEMA:\")\n",
    "print(\"1. Ejecuta todas las celdas anteriores para inicializar el sistema\")\n",
    "print(\"2. El sistema procesar√° autom√°ticamente el video 'calle-dji.MOV'\")\n",
    "print(\"3. Las detecciones se guardar√°n en la carpeta 'outputs/detecciones/'\")\n",
    "print(\"4. Se generar√° un reporte CSV con todas las estad√≠sticas\")\n",
    "print(\"5. Para procesar otro video, usa: process_video_complete('ruta/video.mp4')\")\n",
    "\n",
    "print(\"\\nüìÅ ESTRUCTURA DE SALIDA:\")\n",
    "print(\"outputs/\")\n",
    "print(\"‚îú‚îÄ‚îÄ detecciones/\")\n",
    "print(\"‚îÇ   ‚îú‚îÄ‚îÄ persona/peaton/peque√±o_rojo/\")\n",
    "print(\"‚îÇ   ‚îú‚îÄ‚îÄ carro/sedan/mediano_azul/\")\n",
    "print(\"‚îÇ   ‚îî‚îÄ‚îÄ ...\")\n",
    "print(\"‚îú‚îÄ‚îÄ videos_procesados/\")\n",
    "print(\"‚îú‚îÄ‚îÄ visualizaciones/\")\n",
    "print(\"‚îî‚îÄ‚îÄ logs/\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è NOTAS IMPORTANTES:\")\n",
    "print(\"‚Ä¢ El sistema funciona sin dependencias opcionales (MediaPipe, Tesseract)\")\n",
    "print(\"‚Ä¢ Para mejor rendimiento, instala todas las dependencias\")\n",
    "print(\"‚Ä¢ El procesamiento completo puede tomar varios minutos\")\n",
    "print(\"‚Ä¢ Los resultados se guardan autom√°ticamente\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ SISTEMA LISTO PARA PROCESAR TU VIDEO DJI\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de161db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para Entrenar con Dataset Personalizado\n",
    "def demo_training():\n",
    "    \"\"\"\n",
    "    Demostraci√≥n del proceso de entrenamiento\n",
    "    Nota: Requiere un dataset en formato YOLO\n",
    "    \"\"\"\n",
    "    print(\"\\nüéì DEMOSTRACI√ìN DE ENTRENAMIENTO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Verificar si existe un dataset\n",
    "    dataset_path = \"dataset\"  # Ruta al dataset\n",
    "    if Path(dataset_path).exists():\n",
    "        print(f\"‚úÖ Dataset encontrado: {dataset_path}\")\n",
    "        print(\"   Iniciando entrenamiento...\")\n",
    "        \n",
    "        # Entrenar modelo (comentado para evitar ejecuci√≥n larga)\n",
    "        # model_path = train_model_complete(dataset_path, use_optimization=True)\n",
    "        # print(f\"Modelo entrenado guardado en: {model_path}\")\n",
    "        \n",
    "        print(\"   ‚ö†Ô∏è Entrenamiento deshabilitado en esta demostraci√≥n\")\n",
    "        print(\"   Para entrenar, descomenta las l√≠neas de entrenamiento\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Dataset no encontrado: {dataset_path}\")\n",
    "        print(\"   Para entrenar un modelo personalizado:\")\n",
    "        print(\"   1. Crea un dataset en formato YOLO con la estructura:\")\n",
    "        print(\"      dataset/\")\n",
    "        print(\"      ‚îú‚îÄ‚îÄ images/train/\")\n",
    "        print(\"      ‚îú‚îÄ‚îÄ images/val/\")\n",
    "        print(\"      ‚îú‚îÄ‚îÄ labels/train/\")\n",
    "        print(\"      ‚îî‚îÄ‚îÄ labels/val/\")\n",
    "        print(\"   2. Descomenta las l√≠neas de entrenamiento en la funci√≥n demo_training()\")\n",
    "\n",
    "# Ejecutar demostraci√≥n de entrenamiento\n",
    "demo_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen Final del Sistema\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ SISTEMA AVANZADO DE DETECCI√ìN Y CLASIFICACI√ìN DE OBJETOS - RESUMEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã CARACTER√çSTICAS IMPLEMENTADAS:\")\n",
    "print(\"‚úÖ Entrenamiento YOLOv8 con optimizaci√≥n de hiperpar√°metros\")\n",
    "print(\"‚úÖ Data augmentation avanzada con Albumentations\")\n",
    "print(\"‚úÖ Clasificaci√≥n por tama√±o, color y detalles espec√≠ficos\")\n",
    "print(\"‚úÖ An√°lisis de pose con MediaPipe para personas\")\n",
    "print(\"‚úÖ OCR con Tesseract para se√±ales de tr√°fico\")\n",
    "print(\"‚úÖ Estimaci√≥n de velocidad y orientaci√≥n\")\n",
    "print(\"‚úÖ Anonimizaci√≥n de caras para privacidad\")\n",
    "print(\"‚úÖ Visualizaciones 3D y an√°lisis estad√≠stico\")\n",
    "print(\"‚úÖ Sistema de guardado jer√°rquico con metadata\")\n",
    "print(\"‚úÖ Optimizaciones GPU/CPU autom√°ticas\")\n",
    "print(\"‚úÖ Procesamiento en tiempo real con threading\")\n",
    "print(\"‚úÖ Reportes detallados en JSON y CSV\")\n",
    "\n",
    "print(\"\\nüîß COMPONENTES PRINCIPALES:\")\n",
    "print(\"‚Ä¢ AdvancedYOLOTrainer: Entrenamiento con Optuna\")\n",
    "print(\"‚Ä¢ AdvancedClassifier: Clasificaci√≥n multi-criterio\")\n",
    "print(\"‚Ä¢ AdvancedVisualizer: Gr√°ficos 3D y an√°lisis\")\n",
    "print(\"‚Ä¢ AdvancedVideoProcessor: Pipeline de video optimizado\")\n",
    "print(\"‚Ä¢ AdvancedDataManager: Guardado jer√°rquico\")\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS Y AN√ÅLISIS:\")\n",
    "print(\"‚Ä¢ mAP@0.5:0.95, precisi√≥n, recall, F1-score\")\n",
    "print(\"‚Ä¢ Regresi√≥n lineal m√∫ltiple en 3D\")\n",
    "print(\"‚Ä¢ Heatmaps de correlaci√≥n entre features\")\n",
    "print(\"‚Ä¢ Curvas de aprendizaje detalladas\")\n",
    "print(\"‚Ä¢ Intervalos de confianza estad√≠sticos\")\n",
    "\n",
    "print(\"\\nüöÄ OPTIMIZACIONES:\")\n",
    "print(\"‚Ä¢ Aceleraci√≥n CUDA/TensorRT\")\n",
    "print(\"‚Ä¢ Precisi√≥n FP16 para GPU\")\n",
    "print(\"‚Ä¢ Downsampling inteligente\")\n",
    "print(\"‚Ä¢ Limpieza de memoria autom√°tica\")\n",
    "print(\"‚Ä¢ Procesamiento por lotes\")\n",
    "\n",
    "print(\"\\nüìÅ ESTRUCTURA DE SALIDA:\")\n",
    "print(\"outputs/\")\n",
    "print(\"‚îú‚îÄ‚îÄ detecciones/\")\n",
    "print(\"‚îÇ   ‚îú‚îÄ‚îÄ persona/peaton/peque√±o_rojo/\")\n",
    "print(\"‚îÇ   ‚îú‚îÄ‚îÄ carro/sedan/mediano_azul/\")\n",
    "print(\"‚îÇ   ‚îî‚îÄ‚îÄ ...\")\n",
    "print(\"‚îú‚îÄ‚îÄ videos_procesados/\")\n",
    "print(\"‚îú‚îÄ‚îÄ visualizaciones/\")\n",
    "print(\"‚îî‚îÄ‚îÄ logs/\")\n",
    "\n",
    "print(\"\\nüéØ USO DEL SISTEMA:\")\n",
    "print(\"1. Para procesar video: process_video_complete(video_path)\")\n",
    "print(\"2. Para entrenar modelo: train_model_complete(dataset_path)\")\n",
    "print(\"3. Para visualizaciones: visualizer.create_*_analysis()\")\n",
    "print(\"4. Para reportes: data_manager.generate_summary_report()\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ SISTEMA COMPLETO Y LISTO PARA USO\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
